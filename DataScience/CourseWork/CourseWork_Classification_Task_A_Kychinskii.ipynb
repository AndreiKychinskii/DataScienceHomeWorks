{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Work by Andrei Kychinskii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short description.\n",
    "In this course work is noted my attempt to make a model (i.g. classifier) for activity type recognition.\n",
    "Data from three-axis MEMS accelerometr ('Ax', 'Ay', 'Az') [1] was collected from 36 persons during 6 different person's activities [2]:\n",
    "\n",
    "1. Walking.\n",
    "2. Jogging.\n",
    "3. Upstairs.\n",
    "4. Downstairs.\n",
    "5. Sitting.\n",
    "6. Standing.\n",
    "\n",
    "References:\n",
    "1. MEMS accelerometr, 1 min. video. \n",
    "    https://www.youtube.com/watch?v=RLQGZl0lpjQ\n",
    "2. Original data source.\n",
    "    http://www.cis.fordham.edu/wisdm/dataset.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy  as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acti_df = pd.read_csv( 'H://files/Python/ITEA_Python_4_DataSci/CourseWork/HAR-CNN-Keras/actitracker_raw.txt', header = None, names = columnNames, na_values=';' )\n",
    "\n",
    "columnNames = [ 'Person\\'s ID','Activity Type','Records\\'s ID','Ax','Ay','Az' ]\n",
    "acti_df = pd.read_csv( 'D://ITEA_Python_4_DataSci/CourseWork/HAR-CNN-Keras/actitracker_raw.txt', header = None, names = columnNames, na_values=';' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person's ID</th>\n",
       "      <th>Activity Type</th>\n",
       "      <th>Records's ID</th>\n",
       "      <th>Ax</th>\n",
       "      <th>Ay</th>\n",
       "      <th>Az</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49105962326000</td>\n",
       "      <td>-0.694638</td>\n",
       "      <td>12.680544</td>\n",
       "      <td>0.503953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106062271000</td>\n",
       "      <td>5.012288</td>\n",
       "      <td>11.264028</td>\n",
       "      <td>0.953424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106112167000</td>\n",
       "      <td>4.903325</td>\n",
       "      <td>10.882658</td>\n",
       "      <td>-0.081722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106222305000</td>\n",
       "      <td>-0.612916</td>\n",
       "      <td>18.496431</td>\n",
       "      <td>3.023717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106332290000</td>\n",
       "      <td>-1.184970</td>\n",
       "      <td>12.108489</td>\n",
       "      <td>7.205164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Person's ID Activity Type    Records's ID        Ax         Ay        Az\n",
       "0           33       Jogging  49105962326000 -0.694638  12.680544  0.503953\n",
       "1           33       Jogging  49106062271000  5.012288  11.264028  0.953424\n",
       "2           33       Jogging  49106112167000  4.903325  10.882658 -0.081722\n",
       "3           33       Jogging  49106222305000 -0.612916  18.496431  3.023717\n",
       "4           33       Jogging  49106332290000 -1.184970  12.108489  7.205164"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acti_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1098205 entries, 0 to 1098204\n",
      "Data columns (total 6 columns):\n",
      "Person's ID      1098205 non-null int64\n",
      "Activity Type    1098205 non-null object\n",
      "Records's ID     1098205 non-null int64\n",
      "Ax               1098205 non-null float64\n",
      "Ay               1098205 non-null float64\n",
      "Az               1098204 non-null float64\n",
      "dtypes: float64(3), int64(2), object(1)\n",
      "memory usage: 50.3+ MB\n"
     ]
    }
   ],
   "source": [
    "acti_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person's ID      1098205\n",
       "Activity Type    1098205\n",
       "Records's ID     1098205\n",
       "Ax               1098205\n",
       "Ay               1098205\n",
       "Az               1098204\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acti_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot numbers for every activity type (i.g. data records distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bars = acti_df['Activity Type'].value_counts().to_dict()\n",
    "x = np.arange( len( bars.values() ) )\n",
    "values = bars.values()\n",
    "keys = bars.keys()\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar( x, values, color = [ '#330000', '#550000', '#7D1313', '#AA3939', '#D46A6A', '#FFAAAA' ] )\n",
    "plt.xticks(x, keys )\n",
    "plt.xlabel( 'Activity type',  fontsize = 12 )\n",
    "plt.ylabel( 'Num of records', fontsize = 12 )\n",
    "plt.grid( True )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label-Encoding\n",
    "# Substitute 'Activity Type' to numbers\n",
    "\n",
    "activities_codes = pd.DataFrame( { 'ActivityID'   : [ 1, 2, 3, 4, 5, 6 ],\n",
    "                                   'ActivityName' : [ 'Walking', 'Jogging', 'Upstairs', 'Downstairs', 'Sitting', 'Standing' ] \n",
    "                                 } )\n",
    "activities = activities_codes.groupby( [ 'ActivityName' ] )\n",
    "\n",
    "for key, activity in activities:\n",
    "    acti_df.loc[ acti_df[ 'Activity Type' ]  == key, 'Activity Type' ] = activity[ 'ActivityID' ].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled!..\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN data\n",
    "if( np.any(np.isnan(acti_df)) ):\n",
    "    acti_df.fillna( 0, inplace = True )\n",
    "    print('Filled!..')\n",
    "else:\n",
    "    print('No need to fill!..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person's ID</th>\n",
       "      <th>Activity Type</th>\n",
       "      <th>Records's ID</th>\n",
       "      <th>Ax</th>\n",
       "      <th>Ay</th>\n",
       "      <th>Az</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.098205e+06</td>\n",
       "      <td>1.098205e+06</td>\n",
       "      <td>1.098205e+06</td>\n",
       "      <td>1.098205e+06</td>\n",
       "      <td>1.098205e+06</td>\n",
       "      <td>1.098205e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.886067e+01</td>\n",
       "      <td>2.248334e+00</td>\n",
       "      <td>3.340904e+13</td>\n",
       "      <td>6.628673e-01</td>\n",
       "      <td>7.255633e+00</td>\n",
       "      <td>4.110609e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.021422e+01</td>\n",
       "      <td>1.413767e+00</td>\n",
       "      <td>4.944966e+13</td>\n",
       "      <td>6.849055e+00</td>\n",
       "      <td>6.746205e+00</td>\n",
       "      <td>4.754105e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.961000e+01</td>\n",
       "      <td>-1.961000e+01</td>\n",
       "      <td>-1.980000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.019112e+12</td>\n",
       "      <td>-2.870000e+00</td>\n",
       "      <td>3.170000e+00</td>\n",
       "      <td>-2.220000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>9.722752e+12</td>\n",
       "      <td>2.700000e-01</td>\n",
       "      <td>7.930000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>4.996567e+13</td>\n",
       "      <td>4.440000e+00</td>\n",
       "      <td>1.156000e+01</td>\n",
       "      <td>2.720000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2.093974e+14</td>\n",
       "      <td>1.995000e+01</td>\n",
       "      <td>2.004000e+01</td>\n",
       "      <td>1.961000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Person's ID  Activity Type  Records's ID            Ax            Ay  \\\n",
       "count  1.098205e+06   1.098205e+06  1.098205e+06  1.098205e+06  1.098205e+06   \n",
       "mean   1.886067e+01   2.248334e+00  3.340904e+13  6.628673e-01  7.255633e+00   \n",
       "std    1.021422e+01   1.413767e+00  4.944966e+13  6.849055e+00  6.746205e+00   \n",
       "min    1.000000e+00   1.000000e+00  0.000000e+00 -1.961000e+01 -1.961000e+01   \n",
       "25%    1.000000e+01   1.000000e+00  2.019112e+12 -2.870000e+00  3.170000e+00   \n",
       "50%    1.900000e+01   2.000000e+00  9.722752e+12  2.700000e-01  7.930000e+00   \n",
       "75%    2.800000e+01   3.000000e+00  4.996567e+13  4.440000e+00  1.156000e+01   \n",
       "max    3.600000e+01   6.000000e+00  2.093974e+14  1.995000e+01  2.004000e+01   \n",
       "\n",
       "                 Az  \n",
       "count  1.098205e+06  \n",
       "mean   4.110609e-01  \n",
       "std    4.754105e+00  \n",
       "min   -1.980000e+01  \n",
       "25%   -2.220000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    2.720000e+00  \n",
       "max    1.961000e+01  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acti_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_e405c898_e848_11e9_ae16_b870f4117bb8row0_col0 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row0_col1 {\n",
       "            background-color:  #6687ed;\n",
       "            color:  #000000;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row0_col2 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row0_col3 {\n",
       "            background-color:  #5572df;\n",
       "            color:  #000000;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row0_col4 {\n",
       "            background-color:  #5e7de7;\n",
       "            color:  #000000;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row0_col5 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row1_col0 {\n",
       "            background-color:  #96b7ff;\n",
       "            color:  #000000;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row1_col1 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row1_col2 {\n",
       "            background-color:  #9abbff;\n",
       "            color:  #000000;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row1_col3 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row1_col4 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row1_col5 {\n",
       "            background-color:  #799cf8;\n",
       "            color:  #000000;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row2_col0 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row2_col1 {\n",
       "            background-color:  #6b8df0;\n",
       "            color:  #000000;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row2_col2 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row2_col3 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row2_col4 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row2_col5 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row3_col0 {\n",
       "            background-color:  #8db0fe;\n",
       "            color:  #000000;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row3_col1 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row3_col2 {\n",
       "            background-color:  #7597f6;\n",
       "            color:  #000000;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row3_col3 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row3_col4 {\n",
       "            background-color:  #5a78e4;\n",
       "            color:  #000000;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row3_col5 {\n",
       "            background-color:  #506bda;\n",
       "            color:  #000000;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row4_col0 {\n",
       "            background-color:  #8fb1fe;\n",
       "            color:  #000000;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row4_col1 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row4_col2 {\n",
       "            background-color:  #7093f3;\n",
       "            color:  #000000;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row4_col3 {\n",
       "            background-color:  #536edd;\n",
       "            color:  #000000;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row4_col4 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row4_col5 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row5_col0 {\n",
       "            background-color:  #82a6fb;\n",
       "            color:  #000000;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row5_col1 {\n",
       "            background-color:  #8db0fe;\n",
       "            color:  #000000;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row5_col2 {\n",
       "            background-color:  #8caffe;\n",
       "            color:  #000000;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row5_col3 {\n",
       "            background-color:  #5f7fe8;\n",
       "            color:  #000000;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row5_col4 {\n",
       "            background-color:  #5673e0;\n",
       "            color:  #000000;\n",
       "        }    #T_e405c898_e848_11e9_ae16_b870f4117bb8row5_col5 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Person's ID</th>        <th class=\"col_heading level0 col1\" >Activity Type</th>        <th class=\"col_heading level0 col2\" >Records's ID</th>        <th class=\"col_heading level0 col3\" >Ax</th>        <th class=\"col_heading level0 col4\" >Ay</th>        <th class=\"col_heading level0 col5\" >Az</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8level0_row0\" class=\"row_heading level0 row0\" >Person's ID</th>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row0_col1\" class=\"data row0 col1\" >0.0662</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row0_col2\" class=\"data row0 col2\" >-0.288</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row0_col3\" class=\"data row0 col3\" >0.0349</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row0_col4\" class=\"data row0 col4\" >0.0407</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row0_col5\" class=\"data row0 col5\" >-0.0045</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8level0_row1\" class=\"row_heading level0 row1\" >Activity Type</th>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row1_col0\" class=\"data row1 col0\" >0.0662</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row1_col2\" class=\"data row1 col2\" >0.0823</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row1_col3\" class=\"data row1 col3\" >-0.0547</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row1_col4\" class=\"data row1 col4\" >-0.0835</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row1_col5\" class=\"data row1 col5\" >0.189</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8level0_row2\" class=\"row_heading level0 row2\" >Records's ID</th>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row2_col0\" class=\"data row2 col0\" >-0.288</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row2_col1\" class=\"data row2 col1\" >0.0823</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row2_col2\" class=\"data row2 col2\" >1</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row2_col3\" class=\"data row2 col3\" >-0.0563</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row2_col4\" class=\"data row2 col4\" >-0.0716</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row2_col5\" class=\"data row2 col5\" >0.0336</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8level0_row3\" class=\"row_heading level0 row3\" >Ax</th>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row3_col0\" class=\"data row3 col0\" >0.0349</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row3_col1\" class=\"data row3 col1\" >-0.0547</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row3_col2\" class=\"data row3 col2\" >-0.0563</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row3_col3\" class=\"data row3 col3\" >1</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row3_col4\" class=\"data row3 col4\" >0.0291</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row3_col5\" class=\"data row3 col5\" >0.068</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8level0_row4\" class=\"row_heading level0 row4\" >Ay</th>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row4_col0\" class=\"data row4 col0\" >0.0407</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row4_col1\" class=\"data row4 col1\" >-0.0835</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row4_col2\" class=\"data row4 col2\" >-0.0716</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row4_col3\" class=\"data row4 col3\" >0.0291</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row4_col4\" class=\"data row4 col4\" >1</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row4_col5\" class=\"data row4 col5\" >0.0174</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8level0_row5\" class=\"row_heading level0 row5\" >Az</th>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row5_col0\" class=\"data row5 col0\" >-0.0045</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row5_col1\" class=\"data row5 col1\" >0.189</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row5_col2\" class=\"data row5 col2\" >0.0336</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row5_col3\" class=\"data row5 col3\" >0.068</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row5_col4\" class=\"data row5 col4\" >0.0174</td>\n",
       "                        <td id=\"T_e405c898_e848_11e9_ae16_b870f4117bb8row5_col5\" class=\"data row5 col5\" >1</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x109be5c8>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze data correlation\n",
    "matrix_corr = acti_df.corr()\n",
    "matrix_corr.style.background_gradient(cmap='coolwarm').set_precision(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output:\n",
    "# from matrix_corr table we can see extremely low correlation between Ax, Ay, Ax and Activity Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating additional feature \n",
    "acti_df[ 'A' ] = ( acti_df['Ax'] ** 2 + acti_df['Ay'] ** 2 + acti_df['Az'] ** 2 ) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row0_col0 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row0_col1 {\n",
       "            background-color:  #6b8df0;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row0_col2 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row0_col3 {\n",
       "            background-color:  #5572df;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row0_col4 {\n",
       "            background-color:  #5e7de7;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row0_col5 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row0_col6 {\n",
       "            background-color:  #5673e0;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row1_col0 {\n",
       "            background-color:  #96b7ff;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row1_col1 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row1_col2 {\n",
       "            background-color:  #9abbff;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row1_col3 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row1_col4 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row1_col5 {\n",
       "            background-color:  #799cf8;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row1_col6 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row2_col0 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row2_col1 {\n",
       "            background-color:  #7093f3;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row2_col2 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row2_col3 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row2_col4 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row2_col5 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row2_col6 {\n",
       "            background-color:  #4f69d9;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row3_col0 {\n",
       "            background-color:  #8db0fe;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row3_col1 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row3_col2 {\n",
       "            background-color:  #7597f6;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row3_col3 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row3_col4 {\n",
       "            background-color:  #5a78e4;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row3_col5 {\n",
       "            background-color:  #506bda;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row3_col6 {\n",
       "            background-color:  #6282ea;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row4_col0 {\n",
       "            background-color:  #8fb1fe;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row4_col1 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row4_col2 {\n",
       "            background-color:  #7093f3;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row4_col3 {\n",
       "            background-color:  #536edd;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row4_col4 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row4_col5 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row4_col6 {\n",
       "            background-color:  #e5d8d1;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row5_col0 {\n",
       "            background-color:  #82a6fb;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row5_col1 {\n",
       "            background-color:  #93b5fe;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row5_col2 {\n",
       "            background-color:  #8caffe;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row5_col3 {\n",
       "            background-color:  #5f7fe8;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row5_col4 {\n",
       "            background-color:  #5673e0;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row5_col5 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row5_col6 {\n",
       "            background-color:  #6282ea;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row6_col0 {\n",
       "            background-color:  #82a6fb;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row6_col1 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row6_col2 {\n",
       "            background-color:  #7b9ff9;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row6_col3 {\n",
       "            background-color:  #5572df;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row6_col4 {\n",
       "            background-color:  #e3d9d3;\n",
       "            color:  #000000;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row6_col5 {\n",
       "            background-color:  #465ecf;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_e7e50d1c_e848_11e9_b771_b870f4117bb8row6_col6 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Person's ID</th>        <th class=\"col_heading level0 col1\" >Activity Type</th>        <th class=\"col_heading level0 col2\" >Records's ID</th>        <th class=\"col_heading level0 col3\" >Ax</th>        <th class=\"col_heading level0 col4\" >Ay</th>        <th class=\"col_heading level0 col5\" >Az</th>        <th class=\"col_heading level0 col6\" >A</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8level0_row0\" class=\"row_heading level0 row0\" >Person's ID</th>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row0_col1\" class=\"data row0 col1\" >0.0662</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row0_col2\" class=\"data row0 col2\" >-0.288</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row0_col3\" class=\"data row0 col3\" >0.0349</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row0_col4\" class=\"data row0 col4\" >0.0407</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row0_col5\" class=\"data row0 col5\" >-0.0045</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row0_col6\" class=\"data row0 col6\" >-0.00166</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8level0_row1\" class=\"row_heading level0 row1\" >Activity Type</th>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row1_col0\" class=\"data row1 col0\" >0.0662</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row1_col2\" class=\"data row1 col2\" >0.0823</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row1_col3\" class=\"data row1 col3\" >-0.0547</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row1_col4\" class=\"data row1 col4\" >-0.0835</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row1_col5\" class=\"data row1 col5\" >0.189</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row1_col6\" class=\"data row1 col6\" >-0.105</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8level0_row2\" class=\"row_heading level0 row2\" >Records's ID</th>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row2_col0\" class=\"data row2 col0\" >-0.288</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row2_col1\" class=\"data row2 col1\" >0.0823</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row2_col2\" class=\"data row2 col2\" >1</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row2_col3\" class=\"data row2 col3\" >-0.0563</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row2_col4\" class=\"data row2 col4\" >-0.0716</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row2_col5\" class=\"data row2 col5\" >0.0336</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row2_col6\" class=\"data row2 col6\" >-0.0292</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8level0_row3\" class=\"row_heading level0 row3\" >Ax</th>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row3_col0\" class=\"data row3 col0\" >0.0349</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row3_col1\" class=\"data row3 col1\" >-0.0547</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row3_col2\" class=\"data row3 col2\" >-0.0563</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row3_col3\" class=\"data row3 col3\" >1</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row3_col4\" class=\"data row3 col4\" >0.0291</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row3_col5\" class=\"data row3 col5\" >0.068</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row3_col6\" class=\"data row3 col6\" >0.0365</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8level0_row4\" class=\"row_heading level0 row4\" >Ay</th>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row4_col0\" class=\"data row4 col0\" >0.0407</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row4_col1\" class=\"data row4 col1\" >-0.0835</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row4_col2\" class=\"data row4 col2\" >-0.0716</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row4_col3\" class=\"data row4 col3\" >0.0291</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row4_col4\" class=\"data row4 col4\" >1</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row4_col5\" class=\"data row4 col5\" >0.0174</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row4_col6\" class=\"data row4 col6\" >0.486</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8level0_row5\" class=\"row_heading level0 row5\" >Az</th>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row5_col0\" class=\"data row5 col0\" >-0.0045</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row5_col1\" class=\"data row5 col1\" >0.189</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row5_col2\" class=\"data row5 col2\" >0.0336</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row5_col3\" class=\"data row5 col3\" >0.068</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row5_col4\" class=\"data row5 col4\" >0.0174</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row5_col5\" class=\"data row5 col5\" >1</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row5_col6\" class=\"data row5 col6\" >0.0369</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8level0_row6\" class=\"row_heading level0 row6\" >A</th>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row6_col0\" class=\"data row6 col0\" >-0.00166</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row6_col1\" class=\"data row6 col1\" >-0.105</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row6_col2\" class=\"data row6 col2\" >-0.0292</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row6_col3\" class=\"data row6 col3\" >0.0365</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row6_col4\" class=\"data row6 col4\" >0.486</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row6_col5\" class=\"data row6 col5\" >0.0369</td>\n",
       "                        <td id=\"T_e7e50d1c_e848_11e9_b771_b870f4117bb8row6_col6\" class=\"data row6 col6\" >1</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x109db9c8>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we try agina to analyze data correlation\n",
    "matrix_corr = acti_df.corr()\n",
    "matrix_corr.style.background_gradient(cmap='coolwarm').set_precision(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output:\n",
    "# 'A' is well correlate with 'Ay'.\n",
    "# Possibly, for simple 'Activity Type' model we can use data from 'Ay' only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1098205 entries, 0 to 1098204\n",
      "Data columns (total 7 columns):\n",
      "Person's ID      1098205 non-null int64\n",
      "Activity Type    1098205 non-null int64\n",
      "Records's ID     1098205 non-null int64\n",
      "Ax               1098205 non-null float64\n",
      "Ay               1098205 non-null float64\n",
      "Az               1098205 non-null float64\n",
      "A                1098205 non-null float64\n",
      "dtypes: float64(4), int64(3)\n",
      "memory usage: 58.7 MB\n"
     ]
    }
   ],
   "source": [
    "acti_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "acti_df = acti_df.sample( frac = 1 ).reset_index( drop = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for classifier\n",
    "y = acti_df[ 'Activity Type' ].values\n",
    "\n",
    "if( not np.any(np.isnan(y)) ):\n",
    "    y\n",
    "else:\n",
    "    print('Data contains NaN value(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = acti_df.loc[ : , [ 'Ax', 'Ay', 'Az', 'A' ] ].values\n",
    "# X = acti_df[ 'Ax' ].values\n",
    "# np.any(np.isnan(X))\n",
    "if( not np.any(np.isnan(X)) ):\n",
    "    X\n",
    "else:\n",
    "    print('Data contains NaN value(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split( X, y, test_size = 0.2, random_state = 42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 1, ..., 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 1, ..., 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.23      ,   4.86      ,  -1.92      ,   5.23057358],\n",
       "       [  8.92      ,   9.04      ,  -1.0351465 ,  12.74203784],\n",
       "       [ -0.89      ,  13.53      ,   0.27240697,  13.56197646],\n",
       "       ...,\n",
       "       [  5.83      ,   6.13      ,  -3.11      ,   9.01320698],\n",
       "       [ -2.14      ,   3.79      ,  -3.11      ,   5.3493738 ],\n",
       "       [-15.62      ,  -7.86      ,  14.82      ,  22.921527  ]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.3       ,  9.34      ,  1.0351465 ,  9.95977551],\n",
       "       [ 9.85      , 15.28      ,  3.53      , 18.51922785],\n",
       "       [ 7.55      , 10.19      ,  8.240311  , 15.12419669],\n",
       "       ...,\n",
       "       [ 2.64      , 14.94      , -1.4573772 , 15.24129746],\n",
       "       [-9.47      ,  8.01      ,  2.1111538 , 12.58165213],\n",
       "       [ 1.38      , 14.33      ,  3.6       , 14.83958557]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(878564,), (878564, 4), (219641,), (219641, 4)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ train_y.shape, train_X.shape, test_y.shape, test_X.shape ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN model for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='hamming',\n",
       "                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsClassifier( n_neighbors = 5, metric = \"hamming\", n_jobs = -1 )\n",
    "model.fit( train_X, train_y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# )-:\n",
    "# I have not proceeded success in evaluating the code lines, that noted below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted = model.predict( test_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_p = model.predict_proba( test_X )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "log_reg = LogisticRegression( C = 1.0 )\n",
    "lf = log_reg.fit( train_X, train_y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_lf = lf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5124453084806571\n"
     ]
    }
   ],
   "source": [
    "print( accuracy_score( test_y, pred_y_lf ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5124453084806571\n"
     ]
    }
   ],
   "source": [
    "print( f1_score( test_y, pred_y_lf, average = 'micro' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_p = lf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(roc_auc_score(y_score=predicted_p[:,1], y_true=test_y-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49182 11462   142   657  4067 19496]\n",
      " [19601 30127   204   381  9792  8527]\n",
      " [11611  3072    53   140  1923  7842]\n",
      " [ 9234  1868    30   189  1380  7261]\n",
      " [  712   369     0     0 10632   113]\n",
      " [ 2630   686     0     0     3  6255]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.58      0.55     85006\n",
      "           2       0.63      0.44      0.52     68632\n",
      "           3       0.12      0.00      0.00     24641\n",
      "           4       0.14      0.01      0.02     19962\n",
      "           5       0.38      0.90      0.54     11826\n",
      "           6       0.13      0.65      0.21      9574\n",
      "\n",
      "    accuracy                           0.44    219641\n",
      "   macro avg       0.32      0.43      0.31    219641\n",
      "weighted avg       0.46      0.44      0.42    219641\n",
      "\n",
      "Accuracy: 0.43907102954366445\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression( C=0.01, \n",
    "                             class_weight=\"balanced\",\n",
    "                             n_jobs=-1 )\n",
    "lf = log_reg.fit(train_X, train_y)\n",
    "y_pred = lf.predict(test_X)\n",
    "\n",
    "print(confusion_matrix(test_y, y_pred))\n",
    "print(classification_report(test_y, y_pred))\n",
    "print(\"Accuracy:\", str(accuracy_score(test_y, y_pred)))\n",
    "y_pred_p = lf.predict_proba(test_X)\n",
    "\n",
    "# String below make an error\n",
    "# print(\"AUC: \" + str(roc_auc_score(y_score=y_pred_p[:,1], y_true=test_y-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  - Accuracy score is 0.5124453084806571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5  - Accuracy score is 0.5124453084806571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1  - Accuracy score is 0.5124453084806571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01  - Accuracy score is 0.5124453084806571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001  - Accuracy score is 0.5124453084806571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001  - Accuracy score is 0.5124453084806571\n"
     ]
    }
   ],
   "source": [
    "for i in [ 1, 0.5, 0.1, 0.01, 0.001, 0.0001 ]:\n",
    "    log_reg = LogisticRegression( C = i, class_weight=\"balanced\", n_jobs=-1 )\n",
    "    lf = log_reg.fit( train_X, train_y )\n",
    "    y_pred_lf = lf.predict( test_X )\n",
    "    print( i, ' - Accuracy score is ' + str( accuracy_score( test_y, pred_y_lf ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\а\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\а\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\а\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  - Accuracy score is 0.5632645999608452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\а\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\а\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\а\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5  - Accuracy score is 0.5560437258981702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\а\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=2) \n",
    "\n",
    "X_poly_train = poly_features.fit_transform(train_X)\n",
    "X_poly_test = poly_features.fit_transform(test_X)\n",
    "\n",
    "# for i in [1,0.5,0.1,0.01,0.001,0.0001]:\n",
    "for i in [1,0.5]:\n",
    "    log_reg = LogisticRegression(C=i, class_weight=\"balanced\",n_jobs=-1)\n",
    "    lf = log_reg.fit(X_poly_train, train_y)\n",
    "    pred_y_p = lf.predict(X_poly_test)\n",
    "    print( i, ' - Accuracy score is ' + str( accuracy_score( test_y, pred_y_p ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[70396 13654     0     0   588   368]\n",
      " [21644 45287     0     0  1546   155]\n",
      " [19660  4299     0     1   366   315]\n",
      " [16596  2891     0     0   268   207]\n",
      " [  828   570     0     0 10424     4]\n",
      " [ 8175     4     0     0     0  1395]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\a\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.83      0.63     85006\n",
      "           2       0.68      0.66      0.67     68632\n",
      "           3       0.00      0.00      0.00     24641\n",
      "           4       0.00      0.00      0.00     19962\n",
      "           5       0.79      0.88      0.83     11826\n",
      "           6       0.57      0.15      0.23      9574\n",
      "\n",
      "    accuracy                           0.58    219641\n",
      "   macro avg       0.43      0.42      0.39    219641\n",
      "weighted avg       0.48      0.58      0.51    219641\n",
      "\n",
      "Accuracy: 0.5805018188771678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_clf = Pipeline((\n",
    "        (\"poly_features\", PolynomialFeatures(degree=2)), #1. Створення поліномних фіч\n",
    "        (\"scaler\", StandardScaler()),                    #2. Нормалізація\n",
    "        (\"svm_clf\", LinearSVC(C=1))      #3. Навчання моделі\n",
    "))\n",
    "\n",
    "svm_clf.fit(train_X, train_y)\n",
    "p = svm_clf.predict(test_X)\n",
    "\n",
    "print(confusion_matrix(test_y, p))\n",
    "print(classification_report(test_y, p))\n",
    "print(\"Accuracy:\", str(accuracy_score(test_y, p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA:\n",
      "- accuracy = 0.494525156961, solver='lsqr'\n",
      "- accuracy = 0.494525156961, solver='eigen'\n",
      "- accuracy = 0.494534262729, solver='svd', \n",
      "\n",
      "Max LDA accuracy is: 0.49453426\n"
     ]
    }
   ],
   "source": [
    "# Test solvers:\n",
    "# solver='lsqr'\n",
    "# solver='eigen'\n",
    "# solver='svd'\n",
    "\n",
    "accuracy_score_lsqr = accuracy_score_eigen = accuracy_score_svd = 0\n",
    "\n",
    "clf = LinearDiscriminantAnalysis( solver='lsqr', shrinkage='auto' )\n",
    "clf.fit(train_X, train_y)\n",
    "y_pred_LDA_lsqr = clf.predict(test_X)\n",
    "accuracy_score_lsqr = accuracy_score( test_y, y_pred_LDA_lsqr )\n",
    "\n",
    "clf = LinearDiscriminantAnalysis( solver='eigen', shrinkage='auto' )\n",
    "clf.fit(train_X, train_y)\n",
    "y_pred_LDA_eigen = clf.predict(test_X)\n",
    "accuracy_score_eigen = accuracy_score( test_y, y_pred_LDA_eigen )\n",
    "\n",
    "clf = LinearDiscriminantAnalysis( solver='svd', shrinkage=None )\n",
    "clf.fit(train_X, train_y)\n",
    "y_pred_LDA_svd = clf.predict(test_X)\n",
    "accuracy_score_svd = accuracy_score( test_y, y_pred_LDA_svd )\n",
    "\n",
    "# print(\"AUC: \" + str( roc_auc_score( y_score = y_pred[ : , 1 ], y_true = test_y - 1 ) ) )\n",
    "print(\"LDA:\")\n",
    "print( \"- accuracy = %0.12f, solver='lsqr'\" % accuracy_score_lsqr )\n",
    "print( \"- accuracy = %0.12f, solver='eigen'\" % accuracy_score_eigen )\n",
    "print( \"- accuracy = %0.12f, solver='svd', \" % accuracy_score_svd )\n",
    "print(\"\\nMax LDA accuracy is: %0.8f\" % max( [ accuracy_score_lsqr, accuracy_score_eigen, accuracy_score_svd ] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA, reg_param = 0.00, accuracy = 0.5540\n",
      "QDA, reg_param = 0.01, accuracy = 0.5536\n",
      "QDA, reg_param = 0.05, accuracy = 0.5532\n",
      "QDA, reg_param = 0.10, accuracy = 0.5539\n",
      "QDA, reg_param = 0.20, accuracy = 0.5559\n",
      "QDA, reg_param = 0.30, accuracy = 0.5598\n",
      "QDA, reg_param = 0.40, accuracy = 0.5631\n",
      "QDA, reg_param = 0.50, accuracy = 0.5752\n",
      "QDA, reg_param = 0.60, accuracy = 0.5731\n",
      "QDA, reg_param = 0.70, accuracy = 0.5616\n",
      "QDA, reg_param = 0.80, accuracy = 0.5419\n",
      "QDA, reg_param = 0.90, accuracy = 0.5138\n",
      "QDA, reg_param = 1.00, accuracy = 0.3410\n"
     ]
    }
   ],
   "source": [
    "for _req_param in [ 0.0, 0.01, 0.05 ] + [ i * 0.1 for i in range(1, 11) ]:\n",
    "    clf = QuadraticDiscriminantAnalysis(reg_param=_req_param)\n",
    "    clf.fit(train_X, train_y)\n",
    "    y_pred_QDA = clf.predict(test_X)\n",
    "    print(\"QDA, reg_param = %0.2f, accuracy = %0.4f\" % (_req_param, accuracy_score( test_y, y_pred_QDA ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA, reg_param = 0.40, accuracy = 0.5631\n",
      "QDA, reg_param = 0.41, accuracy = 0.5635\n",
      "QDA, reg_param = 0.42, accuracy = 0.5637\n",
      "QDA, reg_param = 0.43, accuracy = 0.5639\n",
      "QDA, reg_param = 0.44, accuracy = 0.5642\n",
      "QDA, reg_param = 0.45, accuracy = 0.5745\n",
      "QDA, reg_param = 0.46, accuracy = 0.5746\n",
      "QDA, reg_param = 0.47, accuracy = 0.5749\n",
      "QDA, reg_param = 0.48, accuracy = 0.5749\n",
      "QDA, reg_param = 0.49, accuracy = 0.5752\n",
      "QDA, reg_param = 0.50, accuracy = 0.5752\n",
      "QDA, reg_param = 0.51, accuracy = 0.5751\n",
      "QDA, reg_param = 0.52, accuracy = 0.5749\n",
      "QDA, reg_param = 0.53, accuracy = 0.5747\n",
      "QDA, reg_param = 0.54, accuracy = 0.5740\n",
      "QDA, reg_param = 0.55, accuracy = 0.5738\n",
      "QDA, reg_param = 0.56, accuracy = 0.5740\n",
      "QDA, reg_param = 0.57, accuracy = 0.5739\n",
      "QDA, reg_param = 0.58, accuracy = 0.5737\n",
      "QDA, reg_param = 0.59, accuracy = 0.5734\n",
      "QDA, reg_param = 0.60, accuracy = 0.5731\n",
      "\n",
      "Max QDA accuracy is: 0.57522503\n"
     ]
    }
   ],
   "source": [
    "# search for model's accuracy in reg_param belongs to [ 0.4 .. 0.60 ]\n",
    "QDA_accuracies = []\n",
    "for _req_param in [ 0.4 + i * 0.01 for i in range(0, 21) ]:\n",
    "    clf = QuadraticDiscriminantAnalysis(reg_param=_req_param)\n",
    "    clf.fit(train_X, train_y)\n",
    "    y_pred_QDA = clf.predict(test_X)\n",
    "    QDA_accuracy = accuracy_score( test_y, y_pred_QDA )\n",
    "    QDA_accuracies.append( QDA_accuracy )\n",
    "    print(\"QDA, reg_param = %0.2f, accuracy = %0.4f\" % (_req_param, QDA_accuracy ) )\n",
    "print(\"\\nMax QDA accuracy is: %0.8f\" % max(QDA_accuracies) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5835568040575302\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "nb = gnb.fit( train_X, train_y )\n",
    "y_pred_Gaussian = nb.predict( test_X )\n",
    "\n",
    "print(\"Accuracy:\", str( accuracy_score( test_y, y_pred_Gaussian ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5835613569415546\n"
     ]
    }
   ],
   "source": [
    "gnb = BaggingClassifier(GaussianNB(), \n",
    "                        max_features=4, \n",
    "                        max_samples=0.95, \n",
    "                        random_state=42)\n",
    "nb = gnb.fit(train_X, train_y)\n",
    "y_pred_BaggingC = nb.predict(test_X)\n",
    "\n",
    "print(\"Accuracy:\", str( accuracy_score( test_y, y_pred_BaggingC ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4728625347726517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf = BernoulliNB()\n",
    "nb = clf.fit(train_X, train_y)\n",
    "y_pred_BernoulliNB = nb.predict(test_X)\n",
    "\n",
    "print(\"Accuracy:\", str( accuracy_score( test_y, y_pred_BernoulliNB ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6247330871740704\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(\n",
    "    max_depth=10, \n",
    "    min_samples_leaf=21, \n",
    "    max_features=0.9, \n",
    "    criterion=\"gini\",                                    \n",
    "    random_state=1)\n",
    "dt = tree_clf.fit(train_X, train_y)\n",
    "y_pred_dt = dt.predict(test_X)\n",
    "print(\"Accuracy:\", str( accuracy_score( test_y, y_pred_dt ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6- Accuracy: 0.6026060708155582 leaf: 10\n",
      "6- Accuracy: 0.6026060708155582 leaf: 11\n",
      "6- Accuracy: 0.6026151765836069 leaf: 12\n",
      "6- Accuracy: 0.6026151765836069 leaf: 13\n",
      "6- Accuracy: 0.6026151765836069 leaf: 14\n",
      "6- Accuracy: 0.6026151765836069 leaf: 15\n",
      "6- Accuracy: 0.6026151765836069 leaf: 16\n",
      "6- Accuracy: 0.6026151765836069 leaf: 17\n",
      "6- Accuracy: 0.6026151765836069 leaf: 18\n",
      "6- Accuracy: 0.6026151765836069 leaf: 19\n",
      "6- Accuracy: 0.6026151765836069 leaf: 20\n",
      "6- Accuracy: 0.6026151765836069 leaf: 21\n",
      "6- Accuracy: 0.6026151765836069 leaf: 22\n",
      "6- Accuracy: 0.6026151765836069 leaf: 23\n",
      "6- Accuracy: 0.6026151765836069 leaf: 24\n",
      "6- Accuracy: 0.6026151765836069 leaf: 25\n",
      "6- Accuracy: 0.6026151765836069 leaf: 26\n",
      "6- Accuracy: 0.6026151765836069 leaf: 27\n",
      "6- Accuracy: 0.6026151765836069 leaf: 28\n",
      "6- Accuracy: 0.6026151765836069 leaf: 29\n",
      "7- Accuracy: 0.6007894700898284 leaf: 10\n",
      "7- Accuracy: 0.6007894700898284 leaf: 11\n",
      "7- Accuracy: 0.6007894700898284 leaf: 12\n",
      "7- Accuracy: 0.5957403217067851 leaf: 13\n",
      "7- Accuracy: 0.5957403217067851 leaf: 14\n",
      "7- Accuracy: 0.5957403217067851 leaf: 15\n",
      "7- Accuracy: 0.5957403217067851 leaf: 16\n",
      "7- Accuracy: 0.5957403217067851 leaf: 17\n",
      "7- Accuracy: 0.5957403217067851 leaf: 18\n",
      "7- Accuracy: 0.5957403217067851 leaf: 19\n",
      "7- Accuracy: 0.5957403217067851 leaf: 20\n",
      "7- Accuracy: 0.5957403217067851 leaf: 21\n",
      "7- Accuracy: 0.5957403217067851 leaf: 22\n",
      "7- Accuracy: 0.5957403217067851 leaf: 23\n",
      "7- Accuracy: 0.5957403217067851 leaf: 24\n",
      "7- Accuracy: 0.5957403217067851 leaf: 25\n",
      "7- Accuracy: 0.5957403217067851 leaf: 26\n",
      "7- Accuracy: 0.595749427474834 leaf: 27\n",
      "7- Accuracy: 0.595749427474834 leaf: 28\n",
      "7- Accuracy: 0.595749427474834 leaf: 29\n",
      "8- Accuracy: 0.6114067956346948 leaf: 10\n",
      "8- Accuracy: 0.6114022427506705 leaf: 11\n",
      "8- Accuracy: 0.6159778911951775 leaf: 12\n",
      "8- Accuracy: 0.611397689866646 leaf: 13\n",
      "8- Accuracy: 0.6107147572629883 leaf: 14\n",
      "8- Accuracy: 0.6168019632035913 leaf: 15\n",
      "8- Accuracy: 0.6114705360110362 leaf: 16\n",
      "8- Accuracy: 0.6172162756498104 leaf: 17\n",
      "8- Accuracy: 0.6172162756498104 leaf: 18\n",
      "8- Accuracy: 0.6172299343018836 leaf: 19\n",
      "8- Accuracy: 0.6172299343018836 leaf: 20\n",
      "8- Accuracy: 0.6172253814178591 leaf: 21\n",
      "8- Accuracy: 0.6172208285338348 leaf: 22\n",
      "8- Accuracy: 0.617530424647493 leaf: 23\n",
      "8- Accuracy: 0.6176715640522489 leaf: 24\n",
      "8- Accuracy: 0.6176715640522489 leaf: 25\n",
      "8- Accuracy: 0.6176715640522489 leaf: 26\n",
      "8- Accuracy: 0.6176715640522489 leaf: 27\n",
      "8- Accuracy: 0.6176715640522489 leaf: 28\n",
      "8- Accuracy: 0.6176670111682245 leaf: 29\n",
      "9- Accuracy: 0.6199798762526122 leaf: 10\n",
      "9- Accuracy: 0.6219831452233417 leaf: 11\n",
      "9- Accuracy: 0.620426058887002 leaf: 12\n",
      "9- Accuracy: 0.6208267126811479 leaf: 13\n",
      "9- Accuracy: 0.6215642798930983 leaf: 14\n",
      "9- Accuracy: 0.6238134046011446 leaf: 15\n",
      "9- Accuracy: 0.6238088517171202 leaf: 16\n",
      "9- Accuracy: 0.6237177940366325 leaf: 17\n",
      "9- Accuracy: 0.6235994190519984 leaf: 18\n",
      "9- Accuracy: 0.6180312418901753 leaf: 19\n",
      "9- Accuracy: 0.617248145837981 leaf: 20\n",
      "9- Accuracy: 0.6214823279806594 leaf: 21\n",
      "9- Accuracy: 0.6214777750966349 leaf: 22\n",
      "9- Accuracy: 0.6170432660568838 leaf: 23\n",
      "9- Accuracy: 0.6170432660568838 leaf: 24\n",
      "9- Accuracy: 0.6171115593172495 leaf: 25\n",
      "9- Accuracy: 0.618855313898589 leaf: 26\n",
      "9- Accuracy: 0.6214367991404155 leaf: 27\n",
      "9- Accuracy: 0.6214367991404155 leaf: 28\n",
      "9- Accuracy: 0.6214276933723667 leaf: 29\n",
      "10- Accuracy: 0.6233672219667549 leaf: 10\n",
      "10- Accuracy: 0.6261262696855323 leaf: 11\n",
      "10- Accuracy: 0.6258986254843131 leaf: 12\n",
      "10- Accuracy: 0.6261763514098005 leaf: 13\n",
      "10- Accuracy: 0.6276924617899208 leaf: 14\n",
      "10- Accuracy: 0.625803014919801 leaf: 15\n",
      "10- Accuracy: 0.6250517890557774 leaf: 16\n",
      "10- Accuracy: 0.6222244480766341 leaf: 17\n",
      "10- Accuracy: 0.6256982985872401 leaf: 18\n",
      "10- Accuracy: 0.6235356786756571 leaf: 19\n",
      "10- Accuracy: 0.624751298710168 leaf: 20\n",
      "10- Accuracy: 0.6247330871740704 leaf: 21\n",
      "10- Accuracy: 0.6277562021662623 leaf: 22\n",
      "10- Accuracy: 0.6272644906916286 leaf: 23\n",
      "10- Accuracy: 0.626690827304556 leaf: 24\n",
      "10- Accuracy: 0.6274010772123602 leaf: 25\n",
      "10- Accuracy: 0.6232716114022427 leaf: 26\n",
      "10- Accuracy: 0.6222290009606585 leaf: 27\n",
      "10- Accuracy: 0.6255844764866304 leaf: 28\n",
      "10- Accuracy: 0.6224293278577315 leaf: 29\n",
      "11- Accuracy: 0.6282888895971153 leaf: 10\n",
      "11- Accuracy: 0.6295636971239431 leaf: 11\n",
      "11- Accuracy: 0.6316944468473554 leaf: 12\n",
      "11- Accuracy: 0.6307565527383321 leaf: 13\n",
      "11- Accuracy: 0.6289854808528462 leaf: 14\n",
      "11- Accuracy: 0.6292313365901631 leaf: 15\n",
      "11- Accuracy: 0.6310479373158927 leaf: 16\n",
      "11- Accuracy: 0.6287168606954076 leaf: 17\n",
      "11- Accuracy: 0.6287168606954076 leaf: 18\n",
      "11- Accuracy: 0.6292131250540655 leaf: 19\n",
      "11- Accuracy: 0.6318173747160138 leaf: 20\n",
      "11- Accuracy: 0.6277288848621159 leaf: 21\n",
      "11- Accuracy: 0.6277880723544329 leaf: 22\n",
      "11- Accuracy: 0.6314804612982093 leaf: 23\n",
      "11- Accuracy: 0.6266817215365073 leaf: 24\n",
      "11- Accuracy: 0.6300007739902841 leaf: 25\n",
      "11- Accuracy: 0.6252748803729723 leaf: 26\n",
      "11- Accuracy: 0.6296183317322358 leaf: 27\n",
      "11- Accuracy: 0.630046302830528 leaf: 28\n",
      "11- Accuracy: 0.6283936059296762 leaf: 29\n",
      "12- Accuracy: 0.6343214609294258 leaf: 10\n",
      "12- Accuracy: 0.6310707017360146 leaf: 11\n",
      "12- Accuracy: 0.6309204565632099 leaf: 12\n",
      "12- Accuracy: 0.6327689274771103 leaf: 13\n",
      "12- Accuracy: 0.6312346055608925 leaf: 14\n",
      "12- Accuracy: 0.6334700716168657 leaf: 15\n",
      "12- Accuracy: 0.6294999567476017 leaf: 16\n",
      "12- Accuracy: 0.6313074517052827 leaf: 17\n",
      "12- Accuracy: 0.6341029224962552 leaf: 18\n",
      "12- Accuracy: 0.6306700479418688 leaf: 19\n",
      "12- Accuracy: 0.6323455092628425 leaf: 20\n",
      "12- Accuracy: 0.6309477738673562 leaf: 21\n",
      "12- Accuracy: 0.6313393218934534 leaf: 22\n",
      "12- Accuracy: 0.6325959178841838 leaf: 23\n",
      "12- Accuracy: 0.6343078022773526 leaf: 24\n",
      "12- Accuracy: 0.6339799946275968 leaf: 25\n",
      "12- Accuracy: 0.6308111873466247 leaf: 26\n",
      "12- Accuracy: 0.6317672929917456 leaf: 27\n",
      "12- Accuracy: 0.6317627401077213 leaf: 28\n",
      "12- Accuracy: 0.6335247062251583 leaf: 29\n",
      "13- Accuracy: 0.6320177016130868 leaf: 10\n",
      "13- Accuracy: 0.6332651918357683 leaf: 11\n",
      "13- Accuracy: 0.6351910617780834 leaf: 12\n",
      "13- Accuracy: 0.6343943070738159 leaf: 13\n",
      "13- Accuracy: 0.6335429177612558 leaf: 14\n",
      "13- Accuracy: 0.6347585377957667 leaf: 15\n",
      "13- Accuracy: 0.633615763905646 leaf: 16\n",
      "13- Accuracy: 0.6333608024002805 leaf: 17\n",
      "13- Accuracy: 0.6343533311175964 leaf: 18\n",
      "13- Accuracy: 0.6336931629340605 leaf: 19\n",
      "13- Accuracy: 0.6314804612982093 leaf: 20\n",
      "13- Accuracy: 0.634631057043084 leaf: 21\n",
      "13- Accuracy: 0.6323409563788182 leaf: 22\n",
      "13- Accuracy: 0.6343624368856452 leaf: 23\n",
      "13- Accuracy: 0.6341985330607673 leaf: 24\n",
      "13- Accuracy: 0.631571518978697 leaf: 25\n",
      "13- Accuracy: 0.6320450189172331 leaf: 26\n",
      "13- Accuracy: 0.6332879562558903 leaf: 27\n",
      "13- Accuracy: 0.6334655187328413 leaf: 28\n",
      "13- Accuracy: 0.6311253363443073 leaf: 29\n",
      "14- Accuracy: 0.6344990234063768 leaf: 10\n",
      "14- Accuracy: 0.6350408166052787 leaf: 11\n",
      "14- Accuracy: 0.6350408166052787 leaf: 12\n",
      "14- Accuracy: 0.6348541483602789 leaf: 13\n",
      "14- Accuracy: 0.634030076351865 leaf: 14\n",
      "14- Accuracy: 0.6348996772005226 leaf: 15\n",
      "14- Accuracy: 0.6366070087096671 leaf: 16\n",
      "14- Accuracy: 0.6346401628111327 leaf: 17\n",
      "14- Accuracy: 0.6349315473886934 leaf: 18\n",
      "14- Accuracy: 0.6335975523695485 leaf: 19\n",
      "14- Accuracy: 0.6349315473886934 leaf: 20\n",
      "14- Accuracy: 0.6342440619010112 leaf: 21\n",
      "14- Accuracy: 0.6346583743472303 leaf: 22\n",
      "14- Accuracy: 0.6348996772005226 leaf: 23\n",
      "14- Accuracy: 0.6342440619010112 leaf: 24\n",
      "14- Accuracy: 0.6356691146006438 leaf: 25\n",
      "14- Accuracy: 0.634526340710523 leaf: 26\n",
      "14- Accuracy: 0.6352866723425954 leaf: 27\n",
      "14- Accuracy: 0.6362609895238138 leaf: 28\n",
      "14- Accuracy: 0.634808619520035 leaf: 29\n"
     ]
    }
   ],
   "source": [
    "for i in range(6,15):\n",
    "    for j in range(10,30):\n",
    "        tree_clf = DecisionTreeClassifier(max_depth=i, \n",
    "                                          min_samples_leaf=j,\n",
    "                                          max_features=0.9, \n",
    "                                          criterion=\"gini\", random_state=1)  \n",
    "        dt = tree_clf.fit(train_X, train_y)\n",
    "        y_pred_dt = dt.predict(test_X)\n",
    "        print(str(i)+\"- Accuracy: \" + str( accuracy_score( test_y, y_pred_dt ) ) + \" leaf: \"+str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree algo gave no more than 0.637 accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output.\n",
    "Best result for basic classification models is no more than 0.64."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ансамбль алгоритмов (методов) — метод, который использует несколько обучающих алгоритмов с целью получения лучшей\n",
    "эффективности прогнозирования, чем можно было бы получить от каждого обучающего алгоритма по отдельности.\n",
    "http://neerc.ifmo.ru/wiki/index.php?title=Виды_ансамблей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "https://ru.wikipedia.org/wiki/Random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=4, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=-1,\n",
       "                       oob_score=False, random_state=4, verbose=1,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(max_depth=12,\n",
    "                                 n_estimators=60,\n",
    "                                 max_leaf_nodes=None, \n",
    "                                 min_samples_leaf = 4,                                   \n",
    "                                 n_jobs=-1,\n",
    "                                 verbose=1, \n",
    "                                 random_state=4)\n",
    "\n",
    "rnd_clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=3)]: Done  60 out of  60 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = rnd_clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.638792393041372\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest:\")\n",
    "print(\"Accuracy:\", str( accuracy_score( test_y, y_pred_rf ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "\n",
    "# transform classes from [ 1.. 6 ] to [ 0..5 ]\n",
    "train_y = train_y - 1\n",
    "test_y  = test_y - 1\n",
    "\n",
    "train_data = lightgbm.Dataset(train_X, label=train_y)\n",
    "test_data = lightgbm.Dataset(test_X, label=test_y)\n",
    "\n",
    "parameters = {\n",
    "    'objective': 'multiclass', # classification\n",
    "    'num_class': 6, # number of classes\n",
    "    'metric': 'multi_logloss',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'max_depth': 7,\n",
    "    'num_leaves': 40,\n",
    "    'feature_fraction': 0.4,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'bagging_freq': 15,\n",
    "    'learning_rate': 0.01,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.48553\n",
      "Training until validation scores don't improve for 15 rounds.\n",
      "[2]\tvalid_0's multi_logloss: 1.48288\n",
      "[3]\tvalid_0's multi_logloss: 1.48038\n",
      "[4]\tvalid_0's multi_logloss: 1.4778\n",
      "[5]\tvalid_0's multi_logloss: 1.47538\n",
      "[6]\tvalid_0's multi_logloss: 1.47287\n",
      "[7]\tvalid_0's multi_logloss: 1.47051\n",
      "[8]\tvalid_0's multi_logloss: 1.46807\n",
      "[9]\tvalid_0's multi_logloss: 1.46576\n",
      "[10]\tvalid_0's multi_logloss: 1.46338\n",
      "[11]\tvalid_0's multi_logloss: 1.46113\n",
      "[12]\tvalid_0's multi_logloss: 1.45882\n",
      "[13]\tvalid_0's multi_logloss: 1.45662\n",
      "[14]\tvalid_0's multi_logloss: 1.45436\n",
      "[15]\tvalid_0's multi_logloss: 1.45221\n",
      "[16]\tvalid_0's multi_logloss: 1.45003\n",
      "[17]\tvalid_0's multi_logloss: 1.44794\n",
      "[18]\tvalid_0's multi_logloss: 1.44581\n",
      "[19]\tvalid_0's multi_logloss: 1.44376\n",
      "[20]\tvalid_0's multi_logloss: 1.44168\n",
      "[21]\tvalid_0's multi_logloss: 1.43968\n",
      "[22]\tvalid_0's multi_logloss: 1.43765\n",
      "[23]\tvalid_0's multi_logloss: 1.43569\n",
      "[24]\tvalid_0's multi_logloss: 1.4337\n",
      "[25]\tvalid_0's multi_logloss: 1.43181\n",
      "[26]\tvalid_0's multi_logloss: 1.42986\n",
      "[27]\tvalid_0's multi_logloss: 1.428\n",
      "[28]\tvalid_0's multi_logloss: 1.42609\n",
      "[29]\tvalid_0's multi_logloss: 1.42427\n",
      "[30]\tvalid_0's multi_logloss: 1.42241\n",
      "[31]\tvalid_0's multi_logloss: 1.42061\n",
      "[32]\tvalid_0's multi_logloss: 1.41878\n",
      "[33]\tvalid_0's multi_logloss: 1.41702\n",
      "[34]\tvalid_0's multi_logloss: 1.41523\n",
      "[35]\tvalid_0's multi_logloss: 1.4135\n",
      "[36]\tvalid_0's multi_logloss: 1.41175\n",
      "[37]\tvalid_0's multi_logloss: 1.41005\n",
      "[38]\tvalid_0's multi_logloss: 1.40833\n",
      "[39]\tvalid_0's multi_logloss: 1.40668\n",
      "[40]\tvalid_0's multi_logloss: 1.40499\n",
      "[41]\tvalid_0's multi_logloss: 1.40336\n",
      "[42]\tvalid_0's multi_logloss: 1.4017\n",
      "[43]\tvalid_0's multi_logloss: 1.4001\n",
      "[44]\tvalid_0's multi_logloss: 1.39848\n",
      "[45]\tvalid_0's multi_logloss: 1.39691\n",
      "[46]\tvalid_0's multi_logloss: 1.39533\n",
      "[47]\tvalid_0's multi_logloss: 1.39378\n",
      "[48]\tvalid_0's multi_logloss: 1.39222\n",
      "[49]\tvalid_0's multi_logloss: 1.3907\n",
      "[50]\tvalid_0's multi_logloss: 1.38917\n",
      "[51]\tvalid_0's multi_logloss: 1.38767\n",
      "[52]\tvalid_0's multi_logloss: 1.38617\n",
      "[53]\tvalid_0's multi_logloss: 1.3847\n",
      "[54]\tvalid_0's multi_logloss: 1.38323\n",
      "[55]\tvalid_0's multi_logloss: 1.38179\n",
      "[56]\tvalid_0's multi_logloss: 1.38034\n",
      "[57]\tvalid_0's multi_logloss: 1.37892\n",
      "[58]\tvalid_0's multi_logloss: 1.3775\n",
      "[59]\tvalid_0's multi_logloss: 1.37611\n",
      "[60]\tvalid_0's multi_logloss: 1.37471\n",
      "[61]\tvalid_0's multi_logloss: 1.37334\n",
      "[62]\tvalid_0's multi_logloss: 1.37196\n",
      "[63]\tvalid_0's multi_logloss: 1.37062\n",
      "[64]\tvalid_0's multi_logloss: 1.36926\n",
      "[65]\tvalid_0's multi_logloss: 1.36794\n",
      "[66]\tvalid_0's multi_logloss: 1.3666\n",
      "[67]\tvalid_0's multi_logloss: 1.36531\n",
      "[68]\tvalid_0's multi_logloss: 1.364\n",
      "[69]\tvalid_0's multi_logloss: 1.36272\n",
      "[70]\tvalid_0's multi_logloss: 1.36143\n",
      "[71]\tvalid_0's multi_logloss: 1.36018\n",
      "[72]\tvalid_0's multi_logloss: 1.35891\n",
      "[73]\tvalid_0's multi_logloss: 1.35768\n",
      "[74]\tvalid_0's multi_logloss: 1.35644\n",
      "[75]\tvalid_0's multi_logloss: 1.35522\n",
      "[76]\tvalid_0's multi_logloss: 1.354\n",
      "[77]\tvalid_0's multi_logloss: 1.3528\n",
      "[78]\tvalid_0's multi_logloss: 1.35159\n",
      "[79]\tvalid_0's multi_logloss: 1.35041\n",
      "[80]\tvalid_0's multi_logloss: 1.34923\n",
      "[81]\tvalid_0's multi_logloss: 1.34806\n",
      "[82]\tvalid_0's multi_logloss: 1.34689\n",
      "[83]\tvalid_0's multi_logloss: 1.34575\n",
      "[84]\tvalid_0's multi_logloss: 1.3446\n",
      "[85]\tvalid_0's multi_logloss: 1.34347\n",
      "[86]\tvalid_0's multi_logloss: 1.34235\n",
      "[87]\tvalid_0's multi_logloss: 1.34123\n",
      "[88]\tvalid_0's multi_logloss: 1.34012\n",
      "[89]\tvalid_0's multi_logloss: 1.33902\n",
      "[90]\tvalid_0's multi_logloss: 1.33793\n",
      "[91]\tvalid_0's multi_logloss: 1.33685\n",
      "[92]\tvalid_0's multi_logloss: 1.33578\n",
      "[93]\tvalid_0's multi_logloss: 1.33471\n",
      "[94]\tvalid_0's multi_logloss: 1.33366\n",
      "[95]\tvalid_0's multi_logloss: 1.33261\n",
      "[96]\tvalid_0's multi_logloss: 1.33156\n",
      "[97]\tvalid_0's multi_logloss: 1.33053\n",
      "[98]\tvalid_0's multi_logloss: 1.32951\n",
      "[99]\tvalid_0's multi_logloss: 1.32849\n",
      "[100]\tvalid_0's multi_logloss: 1.32748\n",
      "[101]\tvalid_0's multi_logloss: 1.32647\n",
      "[102]\tvalid_0's multi_logloss: 1.32548\n",
      "[103]\tvalid_0's multi_logloss: 1.32449\n",
      "[104]\tvalid_0's multi_logloss: 1.32351\n",
      "[105]\tvalid_0's multi_logloss: 1.32254\n",
      "[106]\tvalid_0's multi_logloss: 1.32157\n",
      "[107]\tvalid_0's multi_logloss: 1.32063\n",
      "[108]\tvalid_0's multi_logloss: 1.31968\n",
      "[109]\tvalid_0's multi_logloss: 1.31876\n",
      "[110]\tvalid_0's multi_logloss: 1.31781\n",
      "[111]\tvalid_0's multi_logloss: 1.31691\n",
      "[112]\tvalid_0's multi_logloss: 1.31598\n",
      "[113]\tvalid_0's multi_logloss: 1.31508\n",
      "[114]\tvalid_0's multi_logloss: 1.31417\n",
      "[115]\tvalid_0's multi_logloss: 1.31328\n",
      "[116]\tvalid_0's multi_logloss: 1.31238\n",
      "[117]\tvalid_0's multi_logloss: 1.31151\n",
      "[118]\tvalid_0's multi_logloss: 1.31062\n",
      "[119]\tvalid_0's multi_logloss: 1.30976\n",
      "[120]\tvalid_0's multi_logloss: 1.30888\n",
      "[121]\tvalid_0's multi_logloss: 1.308\n",
      "[122]\tvalid_0's multi_logloss: 1.30713\n",
      "[123]\tvalid_0's multi_logloss: 1.30627\n",
      "[124]\tvalid_0's multi_logloss: 1.30541\n",
      "[125]\tvalid_0's multi_logloss: 1.30455\n",
      "[126]\tvalid_0's multi_logloss: 1.30371\n",
      "[127]\tvalid_0's multi_logloss: 1.30287\n",
      "[128]\tvalid_0's multi_logloss: 1.30203\n",
      "[129]\tvalid_0's multi_logloss: 1.3012\n",
      "[130]\tvalid_0's multi_logloss: 1.30038\n",
      "[131]\tvalid_0's multi_logloss: 1.29955\n",
      "[132]\tvalid_0's multi_logloss: 1.29874\n",
      "[133]\tvalid_0's multi_logloss: 1.29793\n",
      "[134]\tvalid_0's multi_logloss: 1.29713\n",
      "[135]\tvalid_0's multi_logloss: 1.29633\n",
      "[136]\tvalid_0's multi_logloss: 1.29555\n",
      "[137]\tvalid_0's multi_logloss: 1.29476\n",
      "[138]\tvalid_0's multi_logloss: 1.29398\n",
      "[139]\tvalid_0's multi_logloss: 1.29321\n",
      "[140]\tvalid_0's multi_logloss: 1.29244\n",
      "[141]\tvalid_0's multi_logloss: 1.29168\n",
      "[142]\tvalid_0's multi_logloss: 1.29092\n",
      "[143]\tvalid_0's multi_logloss: 1.29016\n",
      "[144]\tvalid_0's multi_logloss: 1.28942\n",
      "[145]\tvalid_0's multi_logloss: 1.28867\n",
      "[146]\tvalid_0's multi_logloss: 1.28794\n",
      "[147]\tvalid_0's multi_logloss: 1.2872\n",
      "[148]\tvalid_0's multi_logloss: 1.28648\n",
      "[149]\tvalid_0's multi_logloss: 1.28575\n",
      "[150]\tvalid_0's multi_logloss: 1.28503\n",
      "[151]\tvalid_0's multi_logloss: 1.28431\n",
      "[152]\tvalid_0's multi_logloss: 1.28359\n",
      "[153]\tvalid_0's multi_logloss: 1.28288\n",
      "[154]\tvalid_0's multi_logloss: 1.28217\n",
      "[155]\tvalid_0's multi_logloss: 1.28147\n",
      "[156]\tvalid_0's multi_logloss: 1.28077\n",
      "[157]\tvalid_0's multi_logloss: 1.28007\n",
      "[158]\tvalid_0's multi_logloss: 1.27939\n",
      "[159]\tvalid_0's multi_logloss: 1.2787\n",
      "[160]\tvalid_0's multi_logloss: 1.27802\n",
      "[161]\tvalid_0's multi_logloss: 1.27734\n",
      "[162]\tvalid_0's multi_logloss: 1.27667\n",
      "[163]\tvalid_0's multi_logloss: 1.27599\n",
      "[164]\tvalid_0's multi_logloss: 1.27533\n",
      "[165]\tvalid_0's multi_logloss: 1.27467\n",
      "[166]\tvalid_0's multi_logloss: 1.27403\n",
      "[167]\tvalid_0's multi_logloss: 1.27339\n",
      "[168]\tvalid_0's multi_logloss: 1.27275\n",
      "[169]\tvalid_0's multi_logloss: 1.27212\n",
      "[170]\tvalid_0's multi_logloss: 1.27149\n",
      "[171]\tvalid_0's multi_logloss: 1.27087\n",
      "[172]\tvalid_0's multi_logloss: 1.27025\n",
      "[173]\tvalid_0's multi_logloss: 1.26963\n",
      "[174]\tvalid_0's multi_logloss: 1.26902\n",
      "[175]\tvalid_0's multi_logloss: 1.26841\n",
      "[176]\tvalid_0's multi_logloss: 1.2678\n",
      "[177]\tvalid_0's multi_logloss: 1.2672\n",
      "[178]\tvalid_0's multi_logloss: 1.2666\n",
      "[179]\tvalid_0's multi_logloss: 1.266\n",
      "[180]\tvalid_0's multi_logloss: 1.26541\n",
      "[181]\tvalid_0's multi_logloss: 1.26482\n",
      "[182]\tvalid_0's multi_logloss: 1.26423\n",
      "[183]\tvalid_0's multi_logloss: 1.26365\n",
      "[184]\tvalid_0's multi_logloss: 1.26307\n",
      "[185]\tvalid_0's multi_logloss: 1.2625\n",
      "[186]\tvalid_0's multi_logloss: 1.26192\n",
      "[187]\tvalid_0's multi_logloss: 1.26136\n",
      "[188]\tvalid_0's multi_logloss: 1.26079\n",
      "[189]\tvalid_0's multi_logloss: 1.26023\n",
      "[190]\tvalid_0's multi_logloss: 1.25966\n",
      "[191]\tvalid_0's multi_logloss: 1.25911\n",
      "[192]\tvalid_0's multi_logloss: 1.25855\n",
      "[193]\tvalid_0's multi_logloss: 1.25801\n",
      "[194]\tvalid_0's multi_logloss: 1.25746\n",
      "[195]\tvalid_0's multi_logloss: 1.25691\n",
      "[196]\tvalid_0's multi_logloss: 1.25637\n",
      "[197]\tvalid_0's multi_logloss: 1.25584\n",
      "[198]\tvalid_0's multi_logloss: 1.2553\n",
      "[199]\tvalid_0's multi_logloss: 1.25477\n",
      "[200]\tvalid_0's multi_logloss: 1.25424\n",
      "[201]\tvalid_0's multi_logloss: 1.25372\n",
      "[202]\tvalid_0's multi_logloss: 1.25319\n",
      "[203]\tvalid_0's multi_logloss: 1.25267\n",
      "[204]\tvalid_0's multi_logloss: 1.25216\n",
      "[205]\tvalid_0's multi_logloss: 1.25164\n",
      "[206]\tvalid_0's multi_logloss: 1.25113\n",
      "[207]\tvalid_0's multi_logloss: 1.25062\n",
      "[208]\tvalid_0's multi_logloss: 1.25012\n",
      "[209]\tvalid_0's multi_logloss: 1.24961\n",
      "[210]\tvalid_0's multi_logloss: 1.24911\n",
      "[211]\tvalid_0's multi_logloss: 1.24862\n",
      "[212]\tvalid_0's multi_logloss: 1.24812\n",
      "[213]\tvalid_0's multi_logloss: 1.24763\n",
      "[214]\tvalid_0's multi_logloss: 1.24714\n",
      "[215]\tvalid_0's multi_logloss: 1.24665\n",
      "[216]\tvalid_0's multi_logloss: 1.24617\n",
      "[217]\tvalid_0's multi_logloss: 1.24569\n",
      "[218]\tvalid_0's multi_logloss: 1.24521\n",
      "[219]\tvalid_0's multi_logloss: 1.24473\n",
      "[220]\tvalid_0's multi_logloss: 1.24426\n",
      "[221]\tvalid_0's multi_logloss: 1.24379\n",
      "[222]\tvalid_0's multi_logloss: 1.24332\n",
      "[223]\tvalid_0's multi_logloss: 1.24285\n",
      "[224]\tvalid_0's multi_logloss: 1.24239\n",
      "[225]\tvalid_0's multi_logloss: 1.24193\n",
      "[226]\tvalid_0's multi_logloss: 1.24147\n",
      "[227]\tvalid_0's multi_logloss: 1.241\n",
      "[228]\tvalid_0's multi_logloss: 1.24055\n",
      "[229]\tvalid_0's multi_logloss: 1.24009\n",
      "[230]\tvalid_0's multi_logloss: 1.23964\n",
      "[231]\tvalid_0's multi_logloss: 1.23919\n",
      "[232]\tvalid_0's multi_logloss: 1.23875\n",
      "[233]\tvalid_0's multi_logloss: 1.2383\n",
      "[234]\tvalid_0's multi_logloss: 1.23786\n",
      "[235]\tvalid_0's multi_logloss: 1.23741\n",
      "[236]\tvalid_0's multi_logloss: 1.23698\n",
      "[237]\tvalid_0's multi_logloss: 1.23654\n",
      "[238]\tvalid_0's multi_logloss: 1.23611\n",
      "[239]\tvalid_0's multi_logloss: 1.23567\n",
      "[240]\tvalid_0's multi_logloss: 1.23525\n",
      "[241]\tvalid_0's multi_logloss: 1.23482\n",
      "[242]\tvalid_0's multi_logloss: 1.23439\n",
      "[243]\tvalid_0's multi_logloss: 1.23396\n",
      "[244]\tvalid_0's multi_logloss: 1.23355\n",
      "[245]\tvalid_0's multi_logloss: 1.23312\n",
      "[246]\tvalid_0's multi_logloss: 1.23271\n",
      "[247]\tvalid_0's multi_logloss: 1.23229\n",
      "[248]\tvalid_0's multi_logloss: 1.23188\n",
      "[249]\tvalid_0's multi_logloss: 1.23147\n",
      "[250]\tvalid_0's multi_logloss: 1.23106\n",
      "[251]\tvalid_0's multi_logloss: 1.23065\n",
      "[252]\tvalid_0's multi_logloss: 1.23025\n",
      "[253]\tvalid_0's multi_logloss: 1.22984\n",
      "[254]\tvalid_0's multi_logloss: 1.22945\n",
      "[255]\tvalid_0's multi_logloss: 1.22905\n",
      "[256]\tvalid_0's multi_logloss: 1.22865\n",
      "[257]\tvalid_0's multi_logloss: 1.22826\n",
      "[258]\tvalid_0's multi_logloss: 1.22787\n",
      "[259]\tvalid_0's multi_logloss: 1.22747\n",
      "[260]\tvalid_0's multi_logloss: 1.22709\n",
      "[261]\tvalid_0's multi_logloss: 1.2267\n",
      "[262]\tvalid_0's multi_logloss: 1.22632\n",
      "[263]\tvalid_0's multi_logloss: 1.22594\n",
      "[264]\tvalid_0's multi_logloss: 1.22556\n",
      "[265]\tvalid_0's multi_logloss: 1.22518\n",
      "[266]\tvalid_0's multi_logloss: 1.2248\n",
      "[267]\tvalid_0's multi_logloss: 1.22443\n",
      "[268]\tvalid_0's multi_logloss: 1.22406\n",
      "[269]\tvalid_0's multi_logloss: 1.22368\n",
      "[270]\tvalid_0's multi_logloss: 1.22332\n",
      "[271]\tvalid_0's multi_logloss: 1.22295\n",
      "[272]\tvalid_0's multi_logloss: 1.22259\n",
      "[273]\tvalid_0's multi_logloss: 1.22222\n",
      "[274]\tvalid_0's multi_logloss: 1.22187\n",
      "[275]\tvalid_0's multi_logloss: 1.22151\n",
      "[276]\tvalid_0's multi_logloss: 1.22116\n",
      "[277]\tvalid_0's multi_logloss: 1.2208\n",
      "[278]\tvalid_0's multi_logloss: 1.22045\n",
      "[279]\tvalid_0's multi_logloss: 1.2201\n",
      "[280]\tvalid_0's multi_logloss: 1.21975\n",
      "[281]\tvalid_0's multi_logloss: 1.2194\n",
      "[282]\tvalid_0's multi_logloss: 1.21906\n",
      "[283]\tvalid_0's multi_logloss: 1.21871\n",
      "[284]\tvalid_0's multi_logloss: 1.21837\n",
      "[285]\tvalid_0's multi_logloss: 1.21803\n",
      "[286]\tvalid_0's multi_logloss: 1.21769\n",
      "[287]\tvalid_0's multi_logloss: 1.21735\n",
      "[288]\tvalid_0's multi_logloss: 1.21701\n",
      "[289]\tvalid_0's multi_logloss: 1.21667\n",
      "[290]\tvalid_0's multi_logloss: 1.21634\n",
      "[291]\tvalid_0's multi_logloss: 1.21601\n",
      "[292]\tvalid_0's multi_logloss: 1.21568\n",
      "[293]\tvalid_0's multi_logloss: 1.21535\n",
      "[294]\tvalid_0's multi_logloss: 1.21503\n",
      "[295]\tvalid_0's multi_logloss: 1.2147\n",
      "[296]\tvalid_0's multi_logloss: 1.21438\n",
      "[297]\tvalid_0's multi_logloss: 1.21406\n",
      "[298]\tvalid_0's multi_logloss: 1.21374\n",
      "[299]\tvalid_0's multi_logloss: 1.21342\n",
      "[300]\tvalid_0's multi_logloss: 1.21311\n",
      "[301]\tvalid_0's multi_logloss: 1.21278\n",
      "[302]\tvalid_0's multi_logloss: 1.21247\n",
      "[303]\tvalid_0's multi_logloss: 1.21216\n",
      "[304]\tvalid_0's multi_logloss: 1.21185\n",
      "[305]\tvalid_0's multi_logloss: 1.21153\n",
      "[306]\tvalid_0's multi_logloss: 1.21123\n",
      "[307]\tvalid_0's multi_logloss: 1.21091\n",
      "[308]\tvalid_0's multi_logloss: 1.21061\n",
      "[309]\tvalid_0's multi_logloss: 1.21029\n",
      "[310]\tvalid_0's multi_logloss: 1.21\n",
      "[311]\tvalid_0's multi_logloss: 1.20968\n",
      "[312]\tvalid_0's multi_logloss: 1.20939\n",
      "[313]\tvalid_0's multi_logloss: 1.20908\n",
      "[314]\tvalid_0's multi_logloss: 1.20879\n",
      "[315]\tvalid_0's multi_logloss: 1.20848\n",
      "[316]\tvalid_0's multi_logloss: 1.20819\n",
      "[317]\tvalid_0's multi_logloss: 1.2079\n",
      "[318]\tvalid_0's multi_logloss: 1.20761\n",
      "[319]\tvalid_0's multi_logloss: 1.20731\n",
      "[320]\tvalid_0's multi_logloss: 1.20703\n",
      "[321]\tvalid_0's multi_logloss: 1.20674\n",
      "[322]\tvalid_0's multi_logloss: 1.20645\n",
      "[323]\tvalid_0's multi_logloss: 1.20617\n",
      "[324]\tvalid_0's multi_logloss: 1.20589\n",
      "[325]\tvalid_0's multi_logloss: 1.2056\n",
      "[326]\tvalid_0's multi_logloss: 1.20532\n",
      "[327]\tvalid_0's multi_logloss: 1.20504\n",
      "[328]\tvalid_0's multi_logloss: 1.20476\n",
      "[329]\tvalid_0's multi_logloss: 1.20449\n",
      "[330]\tvalid_0's multi_logloss: 1.20421\n",
      "[331]\tvalid_0's multi_logloss: 1.20393\n",
      "[332]\tvalid_0's multi_logloss: 1.20366\n",
      "[333]\tvalid_0's multi_logloss: 1.20339\n",
      "[334]\tvalid_0's multi_logloss: 1.20312\n",
      "[335]\tvalid_0's multi_logloss: 1.20285\n",
      "[336]\tvalid_0's multi_logloss: 1.20258\n",
      "[337]\tvalid_0's multi_logloss: 1.20231\n",
      "[338]\tvalid_0's multi_logloss: 1.20205\n",
      "[339]\tvalid_0's multi_logloss: 1.20178\n",
      "[340]\tvalid_0's multi_logloss: 1.20152\n",
      "[341]\tvalid_0's multi_logloss: 1.20126\n",
      "[342]\tvalid_0's multi_logloss: 1.201\n",
      "[343]\tvalid_0's multi_logloss: 1.20074\n",
      "[344]\tvalid_0's multi_logloss: 1.20048\n",
      "[345]\tvalid_0's multi_logloss: 1.20022\n",
      "[346]\tvalid_0's multi_logloss: 1.19997\n",
      "[347]\tvalid_0's multi_logloss: 1.19971\n",
      "[348]\tvalid_0's multi_logloss: 1.19946\n",
      "[349]\tvalid_0's multi_logloss: 1.1992\n",
      "[350]\tvalid_0's multi_logloss: 1.19895\n",
      "[351]\tvalid_0's multi_logloss: 1.1987\n",
      "[352]\tvalid_0's multi_logloss: 1.19845\n",
      "[353]\tvalid_0's multi_logloss: 1.1982\n",
      "[354]\tvalid_0's multi_logloss: 1.19796\n",
      "[355]\tvalid_0's multi_logloss: 1.19771\n",
      "[356]\tvalid_0's multi_logloss: 1.19747\n",
      "[357]\tvalid_0's multi_logloss: 1.19722\n",
      "[358]\tvalid_0's multi_logloss: 1.19698\n",
      "[359]\tvalid_0's multi_logloss: 1.19674\n",
      "[360]\tvalid_0's multi_logloss: 1.1965\n",
      "[361]\tvalid_0's multi_logloss: 1.19626\n",
      "[362]\tvalid_0's multi_logloss: 1.19602\n",
      "[363]\tvalid_0's multi_logloss: 1.19578\n",
      "[364]\tvalid_0's multi_logloss: 1.19554\n",
      "[365]\tvalid_0's multi_logloss: 1.19531\n",
      "[366]\tvalid_0's multi_logloss: 1.19507\n",
      "[367]\tvalid_0's multi_logloss: 1.19484\n",
      "[368]\tvalid_0's multi_logloss: 1.19461\n",
      "[369]\tvalid_0's multi_logloss: 1.19438\n",
      "[370]\tvalid_0's multi_logloss: 1.19415\n",
      "[371]\tvalid_0's multi_logloss: 1.19392\n",
      "[372]\tvalid_0's multi_logloss: 1.19369\n",
      "[373]\tvalid_0's multi_logloss: 1.19346\n",
      "[374]\tvalid_0's multi_logloss: 1.19324\n",
      "[375]\tvalid_0's multi_logloss: 1.19301\n",
      "[376]\tvalid_0's multi_logloss: 1.19279\n",
      "[377]\tvalid_0's multi_logloss: 1.19256\n",
      "[378]\tvalid_0's multi_logloss: 1.19234\n",
      "[379]\tvalid_0's multi_logloss: 1.19212\n",
      "[380]\tvalid_0's multi_logloss: 1.1919\n",
      "[381]\tvalid_0's multi_logloss: 1.19169\n",
      "[382]\tvalid_0's multi_logloss: 1.19147\n",
      "[383]\tvalid_0's multi_logloss: 1.19126\n",
      "[384]\tvalid_0's multi_logloss: 1.19104\n",
      "[385]\tvalid_0's multi_logloss: 1.19083\n",
      "[386]\tvalid_0's multi_logloss: 1.19061\n",
      "[387]\tvalid_0's multi_logloss: 1.1904\n",
      "[388]\tvalid_0's multi_logloss: 1.19019\n",
      "[389]\tvalid_0's multi_logloss: 1.18998\n",
      "[390]\tvalid_0's multi_logloss: 1.18977\n",
      "[391]\tvalid_0's multi_logloss: 1.18956\n",
      "[392]\tvalid_0's multi_logloss: 1.18935\n",
      "[393]\tvalid_0's multi_logloss: 1.18913\n",
      "[394]\tvalid_0's multi_logloss: 1.18893\n",
      "[395]\tvalid_0's multi_logloss: 1.18871\n",
      "[396]\tvalid_0's multi_logloss: 1.18851\n",
      "[397]\tvalid_0's multi_logloss: 1.1883\n",
      "[398]\tvalid_0's multi_logloss: 1.18809\n",
      "[399]\tvalid_0's multi_logloss: 1.18788\n",
      "[400]\tvalid_0's multi_logloss: 1.18768\n",
      "[401]\tvalid_0's multi_logloss: 1.18747\n",
      "[402]\tvalid_0's multi_logloss: 1.18727\n",
      "[403]\tvalid_0's multi_logloss: 1.18707\n",
      "[404]\tvalid_0's multi_logloss: 1.18687\n",
      "[405]\tvalid_0's multi_logloss: 1.18666\n",
      "[406]\tvalid_0's multi_logloss: 1.18647\n",
      "[407]\tvalid_0's multi_logloss: 1.18627\n",
      "[408]\tvalid_0's multi_logloss: 1.18607\n",
      "[409]\tvalid_0's multi_logloss: 1.18587\n",
      "[410]\tvalid_0's multi_logloss: 1.18568\n",
      "[411]\tvalid_0's multi_logloss: 1.18548\n",
      "[412]\tvalid_0's multi_logloss: 1.18529\n",
      "[413]\tvalid_0's multi_logloss: 1.18509\n",
      "[414]\tvalid_0's multi_logloss: 1.1849\n",
      "[415]\tvalid_0's multi_logloss: 1.18471\n",
      "[416]\tvalid_0's multi_logloss: 1.18452\n",
      "[417]\tvalid_0's multi_logloss: 1.18433\n",
      "[418]\tvalid_0's multi_logloss: 1.18414\n",
      "[419]\tvalid_0's multi_logloss: 1.18395\n",
      "[420]\tvalid_0's multi_logloss: 1.18376\n",
      "[421]\tvalid_0's multi_logloss: 1.18357\n",
      "[422]\tvalid_0's multi_logloss: 1.18339\n",
      "[423]\tvalid_0's multi_logloss: 1.1832\n",
      "[424]\tvalid_0's multi_logloss: 1.18302\n",
      "[425]\tvalid_0's multi_logloss: 1.18283\n",
      "[426]\tvalid_0's multi_logloss: 1.18265\n",
      "[427]\tvalid_0's multi_logloss: 1.18246\n",
      "[428]\tvalid_0's multi_logloss: 1.18228\n",
      "[429]\tvalid_0's multi_logloss: 1.1821\n",
      "[430]\tvalid_0's multi_logloss: 1.18192\n",
      "[431]\tvalid_0's multi_logloss: 1.18174\n",
      "[432]\tvalid_0's multi_logloss: 1.18156\n",
      "[433]\tvalid_0's multi_logloss: 1.18138\n",
      "[434]\tvalid_0's multi_logloss: 1.1812\n",
      "[435]\tvalid_0's multi_logloss: 1.18102\n",
      "[436]\tvalid_0's multi_logloss: 1.18085\n",
      "[437]\tvalid_0's multi_logloss: 1.18067\n",
      "[438]\tvalid_0's multi_logloss: 1.1805\n",
      "[439]\tvalid_0's multi_logloss: 1.18032\n",
      "[440]\tvalid_0's multi_logloss: 1.18015\n",
      "[441]\tvalid_0's multi_logloss: 1.17997\n",
      "[442]\tvalid_0's multi_logloss: 1.1798\n",
      "[443]\tvalid_0's multi_logloss: 1.17963\n",
      "[444]\tvalid_0's multi_logloss: 1.17946\n",
      "[445]\tvalid_0's multi_logloss: 1.17929\n",
      "[446]\tvalid_0's multi_logloss: 1.17912\n",
      "[447]\tvalid_0's multi_logloss: 1.17895\n",
      "[448]\tvalid_0's multi_logloss: 1.17878\n",
      "[449]\tvalid_0's multi_logloss: 1.17861\n",
      "[450]\tvalid_0's multi_logloss: 1.17845\n",
      "[451]\tvalid_0's multi_logloss: 1.17828\n",
      "[452]\tvalid_0's multi_logloss: 1.17812\n",
      "[453]\tvalid_0's multi_logloss: 1.17795\n",
      "[454]\tvalid_0's multi_logloss: 1.17779\n",
      "[455]\tvalid_0's multi_logloss: 1.17762\n",
      "[456]\tvalid_0's multi_logloss: 1.17746\n",
      "[457]\tvalid_0's multi_logloss: 1.1773\n",
      "[458]\tvalid_0's multi_logloss: 1.17714\n",
      "[459]\tvalid_0's multi_logloss: 1.17698\n",
      "[460]\tvalid_0's multi_logloss: 1.17682\n",
      "[461]\tvalid_0's multi_logloss: 1.17666\n",
      "[462]\tvalid_0's multi_logloss: 1.1765\n",
      "[463]\tvalid_0's multi_logloss: 1.17634\n",
      "[464]\tvalid_0's multi_logloss: 1.17618\n",
      "[465]\tvalid_0's multi_logloss: 1.17602\n",
      "[466]\tvalid_0's multi_logloss: 1.17587\n",
      "[467]\tvalid_0's multi_logloss: 1.17571\n",
      "[468]\tvalid_0's multi_logloss: 1.17556\n",
      "[469]\tvalid_0's multi_logloss: 1.1754\n",
      "[470]\tvalid_0's multi_logloss: 1.17525\n",
      "[471]\tvalid_0's multi_logloss: 1.17509\n",
      "[472]\tvalid_0's multi_logloss: 1.17494\n",
      "[473]\tvalid_0's multi_logloss: 1.17479\n",
      "[474]\tvalid_0's multi_logloss: 1.17464\n",
      "[475]\tvalid_0's multi_logloss: 1.17448\n",
      "[476]\tvalid_0's multi_logloss: 1.17434\n",
      "[477]\tvalid_0's multi_logloss: 1.17418\n",
      "[478]\tvalid_0's multi_logloss: 1.17404\n",
      "[479]\tvalid_0's multi_logloss: 1.17389\n",
      "[480]\tvalid_0's multi_logloss: 1.17374\n",
      "[481]\tvalid_0's multi_logloss: 1.17359\n",
      "[482]\tvalid_0's multi_logloss: 1.17344\n",
      "[483]\tvalid_0's multi_logloss: 1.17329\n",
      "[484]\tvalid_0's multi_logloss: 1.17314\n",
      "[485]\tvalid_0's multi_logloss: 1.173\n",
      "[486]\tvalid_0's multi_logloss: 1.17285\n",
      "[487]\tvalid_0's multi_logloss: 1.1727\n",
      "[488]\tvalid_0's multi_logloss: 1.17256\n",
      "[489]\tvalid_0's multi_logloss: 1.17241\n",
      "[490]\tvalid_0's multi_logloss: 1.17227\n",
      "[491]\tvalid_0's multi_logloss: 1.17213\n",
      "[492]\tvalid_0's multi_logloss: 1.17198\n",
      "[493]\tvalid_0's multi_logloss: 1.17184\n",
      "[494]\tvalid_0's multi_logloss: 1.1717\n",
      "[495]\tvalid_0's multi_logloss: 1.17156\n",
      "[496]\tvalid_0's multi_logloss: 1.17142\n",
      "[497]\tvalid_0's multi_logloss: 1.17128\n",
      "[498]\tvalid_0's multi_logloss: 1.17114\n",
      "[499]\tvalid_0's multi_logloss: 1.171\n",
      "[500]\tvalid_0's multi_logloss: 1.17086\n",
      "[501]\tvalid_0's multi_logloss: 1.17073\n",
      "[502]\tvalid_0's multi_logloss: 1.17059\n",
      "[503]\tvalid_0's multi_logloss: 1.17045\n",
      "[504]\tvalid_0's multi_logloss: 1.17032\n",
      "[505]\tvalid_0's multi_logloss: 1.17018\n",
      "[506]\tvalid_0's multi_logloss: 1.17005\n",
      "[507]\tvalid_0's multi_logloss: 1.16991\n",
      "[508]\tvalid_0's multi_logloss: 1.16978\n",
      "[509]\tvalid_0's multi_logloss: 1.16964\n",
      "[510]\tvalid_0's multi_logloss: 1.16951\n",
      "[511]\tvalid_0's multi_logloss: 1.16938\n",
      "[512]\tvalid_0's multi_logloss: 1.16924\n",
      "[513]\tvalid_0's multi_logloss: 1.16911\n",
      "[514]\tvalid_0's multi_logloss: 1.16898\n",
      "[515]\tvalid_0's multi_logloss: 1.16885\n",
      "[516]\tvalid_0's multi_logloss: 1.16872\n",
      "[517]\tvalid_0's multi_logloss: 1.16858\n",
      "[518]\tvalid_0's multi_logloss: 1.16846\n",
      "[519]\tvalid_0's multi_logloss: 1.16832\n",
      "[520]\tvalid_0's multi_logloss: 1.1682\n",
      "[521]\tvalid_0's multi_logloss: 1.16806\n",
      "[522]\tvalid_0's multi_logloss: 1.16794\n",
      "[523]\tvalid_0's multi_logloss: 1.16781\n",
      "[524]\tvalid_0's multi_logloss: 1.16768\n",
      "[525]\tvalid_0's multi_logloss: 1.16755\n",
      "[526]\tvalid_0's multi_logloss: 1.16743\n",
      "[527]\tvalid_0's multi_logloss: 1.1673\n",
      "[528]\tvalid_0's multi_logloss: 1.16717\n",
      "[529]\tvalid_0's multi_logloss: 1.16705\n",
      "[530]\tvalid_0's multi_logloss: 1.16692\n",
      "[531]\tvalid_0's multi_logloss: 1.1668\n",
      "[532]\tvalid_0's multi_logloss: 1.16667\n",
      "[533]\tvalid_0's multi_logloss: 1.16655\n",
      "[534]\tvalid_0's multi_logloss: 1.16643\n",
      "[535]\tvalid_0's multi_logloss: 1.1663\n",
      "[536]\tvalid_0's multi_logloss: 1.16618\n",
      "[537]\tvalid_0's multi_logloss: 1.16606\n",
      "[538]\tvalid_0's multi_logloss: 1.16594\n",
      "[539]\tvalid_0's multi_logloss: 1.16582\n",
      "[540]\tvalid_0's multi_logloss: 1.1657\n",
      "[541]\tvalid_0's multi_logloss: 1.16558\n",
      "[542]\tvalid_0's multi_logloss: 1.16546\n",
      "[543]\tvalid_0's multi_logloss: 1.16534\n",
      "[544]\tvalid_0's multi_logloss: 1.16522\n",
      "[545]\tvalid_0's multi_logloss: 1.1651\n",
      "[546]\tvalid_0's multi_logloss: 1.16498\n",
      "[547]\tvalid_0's multi_logloss: 1.16487\n",
      "[548]\tvalid_0's multi_logloss: 1.16475\n",
      "[549]\tvalid_0's multi_logloss: 1.16463\n",
      "[550]\tvalid_0's multi_logloss: 1.16452\n",
      "[551]\tvalid_0's multi_logloss: 1.1644\n",
      "[552]\tvalid_0's multi_logloss: 1.16428\n",
      "[553]\tvalid_0's multi_logloss: 1.16417\n",
      "[554]\tvalid_0's multi_logloss: 1.16406\n",
      "[555]\tvalid_0's multi_logloss: 1.16394\n",
      "[556]\tvalid_0's multi_logloss: 1.16383\n",
      "[557]\tvalid_0's multi_logloss: 1.16371\n",
      "[558]\tvalid_0's multi_logloss: 1.1636\n",
      "[559]\tvalid_0's multi_logloss: 1.16349\n",
      "[560]\tvalid_0's multi_logloss: 1.16338\n",
      "[561]\tvalid_0's multi_logloss: 1.16327\n",
      "[562]\tvalid_0's multi_logloss: 1.16316\n",
      "[563]\tvalid_0's multi_logloss: 1.16305\n",
      "[564]\tvalid_0's multi_logloss: 1.16293\n",
      "[565]\tvalid_0's multi_logloss: 1.16283\n",
      "[566]\tvalid_0's multi_logloss: 1.16272\n",
      "[567]\tvalid_0's multi_logloss: 1.16261\n",
      "[568]\tvalid_0's multi_logloss: 1.1625\n",
      "[569]\tvalid_0's multi_logloss: 1.16239\n",
      "[570]\tvalid_0's multi_logloss: 1.16228\n",
      "[571]\tvalid_0's multi_logloss: 1.16218\n",
      "[572]\tvalid_0's multi_logloss: 1.16207\n",
      "[573]\tvalid_0's multi_logloss: 1.16196\n",
      "[574]\tvalid_0's multi_logloss: 1.16185\n",
      "[575]\tvalid_0's multi_logloss: 1.16175\n",
      "[576]\tvalid_0's multi_logloss: 1.16164\n",
      "[577]\tvalid_0's multi_logloss: 1.16153\n",
      "[578]\tvalid_0's multi_logloss: 1.16143\n",
      "[579]\tvalid_0's multi_logloss: 1.16132\n",
      "[580]\tvalid_0's multi_logloss: 1.16122\n",
      "[581]\tvalid_0's multi_logloss: 1.16111\n",
      "[582]\tvalid_0's multi_logloss: 1.16101\n",
      "[583]\tvalid_0's multi_logloss: 1.1609\n",
      "[584]\tvalid_0's multi_logloss: 1.1608\n",
      "[585]\tvalid_0's multi_logloss: 1.1607\n",
      "[586]\tvalid_0's multi_logloss: 1.16059\n",
      "[587]\tvalid_0's multi_logloss: 1.16049\n",
      "[588]\tvalid_0's multi_logloss: 1.16039\n",
      "[589]\tvalid_0's multi_logloss: 1.16029\n",
      "[590]\tvalid_0's multi_logloss: 1.16019\n",
      "[591]\tvalid_0's multi_logloss: 1.16009\n",
      "[592]\tvalid_0's multi_logloss: 1.15999\n",
      "[593]\tvalid_0's multi_logloss: 1.15989\n",
      "[594]\tvalid_0's multi_logloss: 1.15979\n",
      "[595]\tvalid_0's multi_logloss: 1.15969\n",
      "[596]\tvalid_0's multi_logloss: 1.15959\n",
      "[597]\tvalid_0's multi_logloss: 1.15949\n",
      "[598]\tvalid_0's multi_logloss: 1.15939\n",
      "[599]\tvalid_0's multi_logloss: 1.15929\n",
      "[600]\tvalid_0's multi_logloss: 1.1592\n",
      "[601]\tvalid_0's multi_logloss: 1.1591\n",
      "[602]\tvalid_0's multi_logloss: 1.159\n",
      "[603]\tvalid_0's multi_logloss: 1.1589\n",
      "[604]\tvalid_0's multi_logloss: 1.1588\n",
      "[605]\tvalid_0's multi_logloss: 1.15871\n",
      "[606]\tvalid_0's multi_logloss: 1.15861\n",
      "[607]\tvalid_0's multi_logloss: 1.15851\n",
      "[608]\tvalid_0's multi_logloss: 1.15842\n",
      "[609]\tvalid_0's multi_logloss: 1.15832\n",
      "[610]\tvalid_0's multi_logloss: 1.15823\n",
      "[611]\tvalid_0's multi_logloss: 1.15813\n",
      "[612]\tvalid_0's multi_logloss: 1.15804\n",
      "[613]\tvalid_0's multi_logloss: 1.15794\n",
      "[614]\tvalid_0's multi_logloss: 1.15785\n",
      "[615]\tvalid_0's multi_logloss: 1.15776\n",
      "[616]\tvalid_0's multi_logloss: 1.15766\n",
      "[617]\tvalid_0's multi_logloss: 1.15757\n",
      "[618]\tvalid_0's multi_logloss: 1.15748\n",
      "[619]\tvalid_0's multi_logloss: 1.15739\n",
      "[620]\tvalid_0's multi_logloss: 1.15729\n",
      "[621]\tvalid_0's multi_logloss: 1.15721\n",
      "[622]\tvalid_0's multi_logloss: 1.15711\n",
      "[623]\tvalid_0's multi_logloss: 1.15702\n",
      "[624]\tvalid_0's multi_logloss: 1.15693\n",
      "[625]\tvalid_0's multi_logloss: 1.15684\n",
      "[626]\tvalid_0's multi_logloss: 1.15675\n",
      "[627]\tvalid_0's multi_logloss: 1.15667\n",
      "[628]\tvalid_0's multi_logloss: 1.15657\n",
      "[629]\tvalid_0's multi_logloss: 1.15649\n",
      "[630]\tvalid_0's multi_logloss: 1.1564\n",
      "[631]\tvalid_0's multi_logloss: 1.15631\n",
      "[632]\tvalid_0's multi_logloss: 1.15622\n",
      "[633]\tvalid_0's multi_logloss: 1.15613\n",
      "[634]\tvalid_0's multi_logloss: 1.15605\n",
      "[635]\tvalid_0's multi_logloss: 1.15596\n",
      "[636]\tvalid_0's multi_logloss: 1.15587\n",
      "[637]\tvalid_0's multi_logloss: 1.15578\n",
      "[638]\tvalid_0's multi_logloss: 1.1557\n",
      "[639]\tvalid_0's multi_logloss: 1.15561\n",
      "[640]\tvalid_0's multi_logloss: 1.15553\n",
      "[641]\tvalid_0's multi_logloss: 1.15544\n",
      "[642]\tvalid_0's multi_logloss: 1.15535\n",
      "[643]\tvalid_0's multi_logloss: 1.15527\n",
      "[644]\tvalid_0's multi_logloss: 1.15518\n",
      "[645]\tvalid_0's multi_logloss: 1.1551\n",
      "[646]\tvalid_0's multi_logloss: 1.15501\n",
      "[647]\tvalid_0's multi_logloss: 1.15493\n",
      "[648]\tvalid_0's multi_logloss: 1.15484\n",
      "[649]\tvalid_0's multi_logloss: 1.15476\n",
      "[650]\tvalid_0's multi_logloss: 1.15467\n",
      "[651]\tvalid_0's multi_logloss: 1.15459\n",
      "[652]\tvalid_0's multi_logloss: 1.15451\n",
      "[653]\tvalid_0's multi_logloss: 1.15442\n",
      "[654]\tvalid_0's multi_logloss: 1.15434\n",
      "[655]\tvalid_0's multi_logloss: 1.15426\n",
      "[656]\tvalid_0's multi_logloss: 1.15417\n",
      "[657]\tvalid_0's multi_logloss: 1.15409\n",
      "[658]\tvalid_0's multi_logloss: 1.15401\n",
      "[659]\tvalid_0's multi_logloss: 1.15393\n",
      "[660]\tvalid_0's multi_logloss: 1.15385\n",
      "[661]\tvalid_0's multi_logloss: 1.15377\n",
      "[662]\tvalid_0's multi_logloss: 1.15368\n",
      "[663]\tvalid_0's multi_logloss: 1.1536\n",
      "[664]\tvalid_0's multi_logloss: 1.15352\n",
      "[665]\tvalid_0's multi_logloss: 1.15344\n",
      "[666]\tvalid_0's multi_logloss: 1.15336\n",
      "[667]\tvalid_0's multi_logloss: 1.15328\n",
      "[668]\tvalid_0's multi_logloss: 1.1532\n",
      "[669]\tvalid_0's multi_logloss: 1.15312\n",
      "[670]\tvalid_0's multi_logloss: 1.15304\n",
      "[671]\tvalid_0's multi_logloss: 1.15296\n",
      "[672]\tvalid_0's multi_logloss: 1.15288\n",
      "[673]\tvalid_0's multi_logloss: 1.1528\n",
      "[674]\tvalid_0's multi_logloss: 1.15272\n",
      "[675]\tvalid_0's multi_logloss: 1.15264\n",
      "[676]\tvalid_0's multi_logloss: 1.15256\n",
      "[677]\tvalid_0's multi_logloss: 1.15249\n",
      "[678]\tvalid_0's multi_logloss: 1.15241\n",
      "[679]\tvalid_0's multi_logloss: 1.15233\n",
      "[680]\tvalid_0's multi_logloss: 1.15226\n",
      "[681]\tvalid_0's multi_logloss: 1.15218\n",
      "[682]\tvalid_0's multi_logloss: 1.1521\n",
      "[683]\tvalid_0's multi_logloss: 1.15203\n",
      "[684]\tvalid_0's multi_logloss: 1.15195\n",
      "[685]\tvalid_0's multi_logloss: 1.15188\n",
      "[686]\tvalid_0's multi_logloss: 1.1518\n",
      "[687]\tvalid_0's multi_logloss: 1.15173\n",
      "[688]\tvalid_0's multi_logloss: 1.15165\n",
      "[689]\tvalid_0's multi_logloss: 1.15158\n",
      "[690]\tvalid_0's multi_logloss: 1.1515\n",
      "[691]\tvalid_0's multi_logloss: 1.15143\n",
      "[692]\tvalid_0's multi_logloss: 1.15135\n",
      "[693]\tvalid_0's multi_logloss: 1.15128\n",
      "[694]\tvalid_0's multi_logloss: 1.15121\n",
      "[695]\tvalid_0's multi_logloss: 1.15114\n",
      "[696]\tvalid_0's multi_logloss: 1.15106\n",
      "[697]\tvalid_0's multi_logloss: 1.15099\n",
      "[698]\tvalid_0's multi_logloss: 1.15092\n",
      "[699]\tvalid_0's multi_logloss: 1.15084\n",
      "[700]\tvalid_0's multi_logloss: 1.15077\n",
      "[701]\tvalid_0's multi_logloss: 1.1507\n",
      "[702]\tvalid_0's multi_logloss: 1.15063\n",
      "[703]\tvalid_0's multi_logloss: 1.15056\n",
      "[704]\tvalid_0's multi_logloss: 1.15048\n",
      "[705]\tvalid_0's multi_logloss: 1.15041\n",
      "[706]\tvalid_0's multi_logloss: 1.15034\n",
      "[707]\tvalid_0's multi_logloss: 1.15027\n",
      "[708]\tvalid_0's multi_logloss: 1.1502\n",
      "[709]\tvalid_0's multi_logloss: 1.15013\n",
      "[710]\tvalid_0's multi_logloss: 1.15006\n",
      "[711]\tvalid_0's multi_logloss: 1.14999\n",
      "[712]\tvalid_0's multi_logloss: 1.14992\n",
      "[713]\tvalid_0's multi_logloss: 1.14985\n",
      "[714]\tvalid_0's multi_logloss: 1.14978\n",
      "[715]\tvalid_0's multi_logloss: 1.14971\n",
      "[716]\tvalid_0's multi_logloss: 1.14964\n",
      "[717]\tvalid_0's multi_logloss: 1.14957\n",
      "[718]\tvalid_0's multi_logloss: 1.1495\n",
      "[719]\tvalid_0's multi_logloss: 1.14943\n",
      "[720]\tvalid_0's multi_logloss: 1.14936\n",
      "[721]\tvalid_0's multi_logloss: 1.1493\n",
      "[722]\tvalid_0's multi_logloss: 1.14923\n",
      "[723]\tvalid_0's multi_logloss: 1.14916\n",
      "[724]\tvalid_0's multi_logloss: 1.14909\n",
      "[725]\tvalid_0's multi_logloss: 1.14903\n",
      "[726]\tvalid_0's multi_logloss: 1.14896\n",
      "[727]\tvalid_0's multi_logloss: 1.1489\n",
      "[728]\tvalid_0's multi_logloss: 1.14883\n",
      "[729]\tvalid_0's multi_logloss: 1.14877\n",
      "[730]\tvalid_0's multi_logloss: 1.1487\n",
      "[731]\tvalid_0's multi_logloss: 1.14864\n",
      "[732]\tvalid_0's multi_logloss: 1.14857\n",
      "[733]\tvalid_0's multi_logloss: 1.14851\n",
      "[734]\tvalid_0's multi_logloss: 1.14844\n",
      "[735]\tvalid_0's multi_logloss: 1.14838\n",
      "[736]\tvalid_0's multi_logloss: 1.14831\n",
      "[737]\tvalid_0's multi_logloss: 1.14825\n",
      "[738]\tvalid_0's multi_logloss: 1.14818\n",
      "[739]\tvalid_0's multi_logloss: 1.14812\n",
      "[740]\tvalid_0's multi_logloss: 1.14806\n",
      "[741]\tvalid_0's multi_logloss: 1.148\n",
      "[742]\tvalid_0's multi_logloss: 1.14793\n",
      "[743]\tvalid_0's multi_logloss: 1.14787\n",
      "[744]\tvalid_0's multi_logloss: 1.14781\n",
      "[745]\tvalid_0's multi_logloss: 1.14775\n",
      "[746]\tvalid_0's multi_logloss: 1.14769\n",
      "[747]\tvalid_0's multi_logloss: 1.14763\n",
      "[748]\tvalid_0's multi_logloss: 1.14756\n",
      "[749]\tvalid_0's multi_logloss: 1.1475\n",
      "[750]\tvalid_0's multi_logloss: 1.14744\n",
      "[751]\tvalid_0's multi_logloss: 1.14738\n",
      "[752]\tvalid_0's multi_logloss: 1.14732\n",
      "[753]\tvalid_0's multi_logloss: 1.14726\n",
      "[754]\tvalid_0's multi_logloss: 1.14719\n",
      "[755]\tvalid_0's multi_logloss: 1.14713\n",
      "[756]\tvalid_0's multi_logloss: 1.14707\n",
      "[757]\tvalid_0's multi_logloss: 1.14701\n",
      "[758]\tvalid_0's multi_logloss: 1.14695\n",
      "[759]\tvalid_0's multi_logloss: 1.14689\n",
      "[760]\tvalid_0's multi_logloss: 1.14683\n",
      "[761]\tvalid_0's multi_logloss: 1.14677\n",
      "[762]\tvalid_0's multi_logloss: 1.14671\n",
      "[763]\tvalid_0's multi_logloss: 1.14665\n",
      "[764]\tvalid_0's multi_logloss: 1.14659\n",
      "[765]\tvalid_0's multi_logloss: 1.14653\n",
      "[766]\tvalid_0's multi_logloss: 1.14647\n",
      "[767]\tvalid_0's multi_logloss: 1.14641\n",
      "[768]\tvalid_0's multi_logloss: 1.14635\n",
      "[769]\tvalid_0's multi_logloss: 1.14629\n",
      "[770]\tvalid_0's multi_logloss: 1.14623\n",
      "[771]\tvalid_0's multi_logloss: 1.14618\n",
      "[772]\tvalid_0's multi_logloss: 1.14612\n",
      "[773]\tvalid_0's multi_logloss: 1.14606\n",
      "[774]\tvalid_0's multi_logloss: 1.146\n",
      "[775]\tvalid_0's multi_logloss: 1.14595\n",
      "[776]\tvalid_0's multi_logloss: 1.14589\n",
      "[777]\tvalid_0's multi_logloss: 1.14584\n",
      "[778]\tvalid_0's multi_logloss: 1.14578\n",
      "[779]\tvalid_0's multi_logloss: 1.14572\n",
      "[780]\tvalid_0's multi_logloss: 1.14566\n",
      "[781]\tvalid_0's multi_logloss: 1.14561\n",
      "[782]\tvalid_0's multi_logloss: 1.14555\n",
      "[783]\tvalid_0's multi_logloss: 1.1455\n",
      "[784]\tvalid_0's multi_logloss: 1.14544\n",
      "[785]\tvalid_0's multi_logloss: 1.14539\n",
      "[786]\tvalid_0's multi_logloss: 1.14533\n",
      "[787]\tvalid_0's multi_logloss: 1.14527\n",
      "[788]\tvalid_0's multi_logloss: 1.14522\n",
      "[789]\tvalid_0's multi_logloss: 1.14516\n",
      "[790]\tvalid_0's multi_logloss: 1.14511\n",
      "[791]\tvalid_0's multi_logloss: 1.14505\n",
      "[792]\tvalid_0's multi_logloss: 1.145\n",
      "[793]\tvalid_0's multi_logloss: 1.14495\n",
      "[794]\tvalid_0's multi_logloss: 1.14489\n",
      "[795]\tvalid_0's multi_logloss: 1.14484\n",
      "[796]\tvalid_0's multi_logloss: 1.14478\n",
      "[797]\tvalid_0's multi_logloss: 1.14473\n",
      "[798]\tvalid_0's multi_logloss: 1.14467\n",
      "[799]\tvalid_0's multi_logloss: 1.14462\n",
      "[800]\tvalid_0's multi_logloss: 1.14457\n",
      "[801]\tvalid_0's multi_logloss: 1.14451\n",
      "[802]\tvalid_0's multi_logloss: 1.14446\n",
      "[803]\tvalid_0's multi_logloss: 1.14441\n",
      "[804]\tvalid_0's multi_logloss: 1.14435\n",
      "[805]\tvalid_0's multi_logloss: 1.1443\n",
      "[806]\tvalid_0's multi_logloss: 1.14425\n",
      "[807]\tvalid_0's multi_logloss: 1.1442\n",
      "[808]\tvalid_0's multi_logloss: 1.14414\n",
      "[809]\tvalid_0's multi_logloss: 1.14409\n",
      "[810]\tvalid_0's multi_logloss: 1.14404\n",
      "[811]\tvalid_0's multi_logloss: 1.14399\n",
      "[812]\tvalid_0's multi_logloss: 1.14393\n",
      "[813]\tvalid_0's multi_logloss: 1.14389\n",
      "[814]\tvalid_0's multi_logloss: 1.14383\n",
      "[815]\tvalid_0's multi_logloss: 1.14378\n",
      "[816]\tvalid_0's multi_logloss: 1.14373\n",
      "[817]\tvalid_0's multi_logloss: 1.14368\n",
      "[818]\tvalid_0's multi_logloss: 1.14363\n",
      "[819]\tvalid_0's multi_logloss: 1.14358\n",
      "[820]\tvalid_0's multi_logloss: 1.14352\n",
      "[821]\tvalid_0's multi_logloss: 1.14347\n",
      "[822]\tvalid_0's multi_logloss: 1.14342\n",
      "[823]\tvalid_0's multi_logloss: 1.14337\n",
      "[824]\tvalid_0's multi_logloss: 1.14332\n",
      "[825]\tvalid_0's multi_logloss: 1.14327\n",
      "[826]\tvalid_0's multi_logloss: 1.14322\n",
      "[827]\tvalid_0's multi_logloss: 1.14317\n",
      "[828]\tvalid_0's multi_logloss: 1.14312\n",
      "[829]\tvalid_0's multi_logloss: 1.14307\n",
      "[830]\tvalid_0's multi_logloss: 1.14302\n",
      "[831]\tvalid_0's multi_logloss: 1.14298\n",
      "[832]\tvalid_0's multi_logloss: 1.14293\n",
      "[833]\tvalid_0's multi_logloss: 1.14288\n",
      "[834]\tvalid_0's multi_logloss: 1.14283\n",
      "[835]\tvalid_0's multi_logloss: 1.14278\n",
      "[836]\tvalid_0's multi_logloss: 1.14273\n",
      "[837]\tvalid_0's multi_logloss: 1.14269\n",
      "[838]\tvalid_0's multi_logloss: 1.14264\n",
      "[839]\tvalid_0's multi_logloss: 1.14259\n",
      "[840]\tvalid_0's multi_logloss: 1.14255\n",
      "[841]\tvalid_0's multi_logloss: 1.1425\n",
      "[842]\tvalid_0's multi_logloss: 1.14245\n",
      "[843]\tvalid_0's multi_logloss: 1.1424\n",
      "[844]\tvalid_0's multi_logloss: 1.14235\n",
      "[845]\tvalid_0's multi_logloss: 1.1423\n",
      "[846]\tvalid_0's multi_logloss: 1.14225\n",
      "[847]\tvalid_0's multi_logloss: 1.14221\n",
      "[848]\tvalid_0's multi_logloss: 1.14216\n",
      "[849]\tvalid_0's multi_logloss: 1.14211\n",
      "[850]\tvalid_0's multi_logloss: 1.14206\n",
      "[851]\tvalid_0's multi_logloss: 1.14201\n",
      "[852]\tvalid_0's multi_logloss: 1.14197\n",
      "[853]\tvalid_0's multi_logloss: 1.14192\n",
      "[854]\tvalid_0's multi_logloss: 1.14187\n",
      "[855]\tvalid_0's multi_logloss: 1.14183\n",
      "[856]\tvalid_0's multi_logloss: 1.14178\n",
      "[857]\tvalid_0's multi_logloss: 1.14174\n",
      "[858]\tvalid_0's multi_logloss: 1.14169\n",
      "[859]\tvalid_0's multi_logloss: 1.14164\n",
      "[860]\tvalid_0's multi_logloss: 1.1416\n",
      "[861]\tvalid_0's multi_logloss: 1.14155\n",
      "[862]\tvalid_0's multi_logloss: 1.14151\n",
      "[863]\tvalid_0's multi_logloss: 1.14146\n",
      "[864]\tvalid_0's multi_logloss: 1.14142\n",
      "[865]\tvalid_0's multi_logloss: 1.14137\n",
      "[866]\tvalid_0's multi_logloss: 1.14133\n",
      "[867]\tvalid_0's multi_logloss: 1.14129\n",
      "[868]\tvalid_0's multi_logloss: 1.14124\n",
      "[869]\tvalid_0's multi_logloss: 1.1412\n",
      "[870]\tvalid_0's multi_logloss: 1.14115\n",
      "[871]\tvalid_0's multi_logloss: 1.14111\n",
      "[872]\tvalid_0's multi_logloss: 1.14106\n",
      "[873]\tvalid_0's multi_logloss: 1.14102\n",
      "[874]\tvalid_0's multi_logloss: 1.14098\n",
      "[875]\tvalid_0's multi_logloss: 1.14093\n",
      "[876]\tvalid_0's multi_logloss: 1.14089\n",
      "[877]\tvalid_0's multi_logloss: 1.14085\n",
      "[878]\tvalid_0's multi_logloss: 1.1408\n",
      "[879]\tvalid_0's multi_logloss: 1.14076\n",
      "[880]\tvalid_0's multi_logloss: 1.14072\n",
      "[881]\tvalid_0's multi_logloss: 1.14068\n",
      "[882]\tvalid_0's multi_logloss: 1.14063\n",
      "[883]\tvalid_0's multi_logloss: 1.14059\n",
      "[884]\tvalid_0's multi_logloss: 1.14055\n",
      "[885]\tvalid_0's multi_logloss: 1.14051\n",
      "[886]\tvalid_0's multi_logloss: 1.14046\n",
      "[887]\tvalid_0's multi_logloss: 1.14042\n",
      "[888]\tvalid_0's multi_logloss: 1.14038\n",
      "[889]\tvalid_0's multi_logloss: 1.14034\n",
      "[890]\tvalid_0's multi_logloss: 1.14029\n",
      "[891]\tvalid_0's multi_logloss: 1.14025\n",
      "[892]\tvalid_0's multi_logloss: 1.14021\n",
      "[893]\tvalid_0's multi_logloss: 1.14017\n",
      "[894]\tvalid_0's multi_logloss: 1.14012\n",
      "[895]\tvalid_0's multi_logloss: 1.14009\n",
      "[896]\tvalid_0's multi_logloss: 1.14004\n",
      "[897]\tvalid_0's multi_logloss: 1.14\n",
      "[898]\tvalid_0's multi_logloss: 1.13996\n",
      "[899]\tvalid_0's multi_logloss: 1.13992\n",
      "[900]\tvalid_0's multi_logloss: 1.13988\n",
      "[901]\tvalid_0's multi_logloss: 1.13984\n",
      "[902]\tvalid_0's multi_logloss: 1.13979\n",
      "[903]\tvalid_0's multi_logloss: 1.13975\n",
      "[904]\tvalid_0's multi_logloss: 1.13971\n",
      "[905]\tvalid_0's multi_logloss: 1.13967\n",
      "[906]\tvalid_0's multi_logloss: 1.13963\n",
      "[907]\tvalid_0's multi_logloss: 1.13959\n",
      "[908]\tvalid_0's multi_logloss: 1.13955\n",
      "[909]\tvalid_0's multi_logloss: 1.13951\n",
      "[910]\tvalid_0's multi_logloss: 1.13946\n",
      "[911]\tvalid_0's multi_logloss: 1.13943\n",
      "[912]\tvalid_0's multi_logloss: 1.13938\n",
      "[913]\tvalid_0's multi_logloss: 1.13935\n",
      "[914]\tvalid_0's multi_logloss: 1.1393\n",
      "[915]\tvalid_0's multi_logloss: 1.13927\n",
      "[916]\tvalid_0's multi_logloss: 1.13922\n",
      "[917]\tvalid_0's multi_logloss: 1.13919\n",
      "[918]\tvalid_0's multi_logloss: 1.13915\n",
      "[919]\tvalid_0's multi_logloss: 1.13911\n",
      "[920]\tvalid_0's multi_logloss: 1.13907\n",
      "[921]\tvalid_0's multi_logloss: 1.13903\n",
      "[922]\tvalid_0's multi_logloss: 1.13899\n",
      "[923]\tvalid_0's multi_logloss: 1.13895\n",
      "[924]\tvalid_0's multi_logloss: 1.13891\n",
      "[925]\tvalid_0's multi_logloss: 1.13888\n",
      "[926]\tvalid_0's multi_logloss: 1.13884\n",
      "[927]\tvalid_0's multi_logloss: 1.1388\n",
      "[928]\tvalid_0's multi_logloss: 1.13876\n",
      "[929]\tvalid_0's multi_logloss: 1.13872\n",
      "[930]\tvalid_0's multi_logloss: 1.13868\n",
      "[931]\tvalid_0's multi_logloss: 1.13865\n",
      "[932]\tvalid_0's multi_logloss: 1.13861\n",
      "[933]\tvalid_0's multi_logloss: 1.13857\n",
      "[934]\tvalid_0's multi_logloss: 1.13854\n",
      "[935]\tvalid_0's multi_logloss: 1.1385\n",
      "[936]\tvalid_0's multi_logloss: 1.13846\n",
      "[937]\tvalid_0's multi_logloss: 1.13843\n",
      "[938]\tvalid_0's multi_logloss: 1.13839\n",
      "[939]\tvalid_0's multi_logloss: 1.13835\n",
      "[940]\tvalid_0's multi_logloss: 1.13832\n",
      "[941]\tvalid_0's multi_logloss: 1.13828\n",
      "[942]\tvalid_0's multi_logloss: 1.13824\n",
      "[943]\tvalid_0's multi_logloss: 1.13821\n",
      "[944]\tvalid_0's multi_logloss: 1.13817\n",
      "[945]\tvalid_0's multi_logloss: 1.13814\n",
      "[946]\tvalid_0's multi_logloss: 1.1381\n",
      "[947]\tvalid_0's multi_logloss: 1.13807\n",
      "[948]\tvalid_0's multi_logloss: 1.13803\n",
      "[949]\tvalid_0's multi_logloss: 1.13799\n",
      "[950]\tvalid_0's multi_logloss: 1.13796\n",
      "[951]\tvalid_0's multi_logloss: 1.13792\n",
      "[952]\tvalid_0's multi_logloss: 1.13789\n",
      "[953]\tvalid_0's multi_logloss: 1.13785\n",
      "[954]\tvalid_0's multi_logloss: 1.13782\n",
      "[955]\tvalid_0's multi_logloss: 1.13778\n",
      "[956]\tvalid_0's multi_logloss: 1.13775\n",
      "[957]\tvalid_0's multi_logloss: 1.13771\n",
      "[958]\tvalid_0's multi_logloss: 1.13768\n",
      "[959]\tvalid_0's multi_logloss: 1.13765\n",
      "[960]\tvalid_0's multi_logloss: 1.13761\n",
      "[961]\tvalid_0's multi_logloss: 1.13757\n",
      "[962]\tvalid_0's multi_logloss: 1.13754\n",
      "[963]\tvalid_0's multi_logloss: 1.1375\n",
      "[964]\tvalid_0's multi_logloss: 1.13747\n",
      "[965]\tvalid_0's multi_logloss: 1.13743\n",
      "[966]\tvalid_0's multi_logloss: 1.1374\n",
      "[967]\tvalid_0's multi_logloss: 1.13736\n",
      "[968]\tvalid_0's multi_logloss: 1.13733\n",
      "[969]\tvalid_0's multi_logloss: 1.13729\n",
      "[970]\tvalid_0's multi_logloss: 1.13726\n",
      "[971]\tvalid_0's multi_logloss: 1.13722\n",
      "[972]\tvalid_0's multi_logloss: 1.13719\n",
      "[973]\tvalid_0's multi_logloss: 1.13715\n",
      "[974]\tvalid_0's multi_logloss: 1.13712\n",
      "[975]\tvalid_0's multi_logloss: 1.13709\n",
      "[976]\tvalid_0's multi_logloss: 1.13705\n",
      "[977]\tvalid_0's multi_logloss: 1.13702\n",
      "[978]\tvalid_0's multi_logloss: 1.13698\n",
      "[979]\tvalid_0's multi_logloss: 1.13695\n",
      "[980]\tvalid_0's multi_logloss: 1.13692\n",
      "[981]\tvalid_0's multi_logloss: 1.13689\n",
      "[982]\tvalid_0's multi_logloss: 1.13685\n",
      "[983]\tvalid_0's multi_logloss: 1.13682\n",
      "[984]\tvalid_0's multi_logloss: 1.13679\n",
      "[985]\tvalid_0's multi_logloss: 1.13676\n",
      "[986]\tvalid_0's multi_logloss: 1.13672\n",
      "[987]\tvalid_0's multi_logloss: 1.13669\n",
      "[988]\tvalid_0's multi_logloss: 1.13666\n",
      "[989]\tvalid_0's multi_logloss: 1.13663\n",
      "[990]\tvalid_0's multi_logloss: 1.1366\n",
      "[991]\tvalid_0's multi_logloss: 1.13657\n",
      "[992]\tvalid_0's multi_logloss: 1.13653\n",
      "[993]\tvalid_0's multi_logloss: 1.1365\n",
      "[994]\tvalid_0's multi_logloss: 1.13647\n",
      "[995]\tvalid_0's multi_logloss: 1.13644\n",
      "[996]\tvalid_0's multi_logloss: 1.1364\n",
      "[997]\tvalid_0's multi_logloss: 1.13637\n",
      "[998]\tvalid_0's multi_logloss: 1.13634\n",
      "[999]\tvalid_0's multi_logloss: 1.13631\n",
      "[1000]\tvalid_0's multi_logloss: 1.13627\n",
      "[1001]\tvalid_0's multi_logloss: 1.13624\n",
      "[1002]\tvalid_0's multi_logloss: 1.13621\n",
      "[1003]\tvalid_0's multi_logloss: 1.13618\n",
      "[1004]\tvalid_0's multi_logloss: 1.13615\n",
      "[1005]\tvalid_0's multi_logloss: 1.13612\n",
      "[1006]\tvalid_0's multi_logloss: 1.13609\n",
      "[1007]\tvalid_0's multi_logloss: 1.13606\n",
      "[1008]\tvalid_0's multi_logloss: 1.13603\n",
      "[1009]\tvalid_0's multi_logloss: 1.136\n",
      "[1010]\tvalid_0's multi_logloss: 1.13597\n",
      "[1011]\tvalid_0's multi_logloss: 1.13594\n",
      "[1012]\tvalid_0's multi_logloss: 1.13591\n",
      "[1013]\tvalid_0's multi_logloss: 1.13588\n",
      "[1014]\tvalid_0's multi_logloss: 1.13585\n",
      "[1015]\tvalid_0's multi_logloss: 1.13582\n",
      "[1016]\tvalid_0's multi_logloss: 1.13579\n",
      "[1017]\tvalid_0's multi_logloss: 1.13576\n",
      "[1018]\tvalid_0's multi_logloss: 1.13573\n",
      "[1019]\tvalid_0's multi_logloss: 1.1357\n",
      "[1020]\tvalid_0's multi_logloss: 1.13567\n",
      "[1021]\tvalid_0's multi_logloss: 1.13564\n",
      "[1022]\tvalid_0's multi_logloss: 1.13561\n",
      "[1023]\tvalid_0's multi_logloss: 1.13558\n",
      "[1024]\tvalid_0's multi_logloss: 1.13555\n",
      "[1025]\tvalid_0's multi_logloss: 1.13552\n",
      "[1026]\tvalid_0's multi_logloss: 1.13549\n",
      "[1027]\tvalid_0's multi_logloss: 1.13546\n",
      "[1028]\tvalid_0's multi_logloss: 1.13543\n",
      "[1029]\tvalid_0's multi_logloss: 1.1354\n",
      "[1030]\tvalid_0's multi_logloss: 1.13537\n",
      "[1031]\tvalid_0's multi_logloss: 1.13534\n",
      "[1032]\tvalid_0's multi_logloss: 1.13531\n",
      "[1033]\tvalid_0's multi_logloss: 1.13529\n",
      "[1034]\tvalid_0's multi_logloss: 1.13525\n",
      "[1035]\tvalid_0's multi_logloss: 1.13523\n",
      "[1036]\tvalid_0's multi_logloss: 1.1352\n",
      "[1037]\tvalid_0's multi_logloss: 1.13517\n",
      "[1038]\tvalid_0's multi_logloss: 1.13514\n",
      "[1039]\tvalid_0's multi_logloss: 1.13512\n",
      "[1040]\tvalid_0's multi_logloss: 1.13509\n",
      "[1041]\tvalid_0's multi_logloss: 1.13506\n",
      "[1042]\tvalid_0's multi_logloss: 1.13503\n",
      "[1043]\tvalid_0's multi_logloss: 1.135\n",
      "[1044]\tvalid_0's multi_logloss: 1.13498\n",
      "[1045]\tvalid_0's multi_logloss: 1.13495\n",
      "[1046]\tvalid_0's multi_logloss: 1.13492\n",
      "[1047]\tvalid_0's multi_logloss: 1.13489\n",
      "[1048]\tvalid_0's multi_logloss: 1.13487\n",
      "[1049]\tvalid_0's multi_logloss: 1.13484\n",
      "[1050]\tvalid_0's multi_logloss: 1.13481\n",
      "[1051]\tvalid_0's multi_logloss: 1.13479\n",
      "[1052]\tvalid_0's multi_logloss: 1.13476\n",
      "[1053]\tvalid_0's multi_logloss: 1.13473\n",
      "[1054]\tvalid_0's multi_logloss: 1.1347\n",
      "[1055]\tvalid_0's multi_logloss: 1.13468\n",
      "[1056]\tvalid_0's multi_logloss: 1.13465\n",
      "[1057]\tvalid_0's multi_logloss: 1.13463\n",
      "[1058]\tvalid_0's multi_logloss: 1.1346\n",
      "[1059]\tvalid_0's multi_logloss: 1.13457\n",
      "[1060]\tvalid_0's multi_logloss: 1.13454\n",
      "[1061]\tvalid_0's multi_logloss: 1.13452\n",
      "[1062]\tvalid_0's multi_logloss: 1.13449\n",
      "[1063]\tvalid_0's multi_logloss: 1.13447\n",
      "[1064]\tvalid_0's multi_logloss: 1.13444\n",
      "[1065]\tvalid_0's multi_logloss: 1.13442\n",
      "[1066]\tvalid_0's multi_logloss: 1.13439\n",
      "[1067]\tvalid_0's multi_logloss: 1.13436\n",
      "[1068]\tvalid_0's multi_logloss: 1.13433\n",
      "[1069]\tvalid_0's multi_logloss: 1.13431\n",
      "[1070]\tvalid_0's multi_logloss: 1.13428\n",
      "[1071]\tvalid_0's multi_logloss: 1.13425\n",
      "[1072]\tvalid_0's multi_logloss: 1.13423\n",
      "[1073]\tvalid_0's multi_logloss: 1.1342\n",
      "[1074]\tvalid_0's multi_logloss: 1.13417\n",
      "[1075]\tvalid_0's multi_logloss: 1.13415\n",
      "[1076]\tvalid_0's multi_logloss: 1.13412\n",
      "[1077]\tvalid_0's multi_logloss: 1.13409\n",
      "[1078]\tvalid_0's multi_logloss: 1.13407\n",
      "[1079]\tvalid_0's multi_logloss: 1.13404\n",
      "[1080]\tvalid_0's multi_logloss: 1.13401\n",
      "[1081]\tvalid_0's multi_logloss: 1.13399\n",
      "[1082]\tvalid_0's multi_logloss: 1.13396\n",
      "[1083]\tvalid_0's multi_logloss: 1.13394\n",
      "[1084]\tvalid_0's multi_logloss: 1.13391\n",
      "[1085]\tvalid_0's multi_logloss: 1.13389\n",
      "[1086]\tvalid_0's multi_logloss: 1.13386\n",
      "[1087]\tvalid_0's multi_logloss: 1.13384\n",
      "[1088]\tvalid_0's multi_logloss: 1.13381\n",
      "[1089]\tvalid_0's multi_logloss: 1.13379\n",
      "[1090]\tvalid_0's multi_logloss: 1.13376\n",
      "[1091]\tvalid_0's multi_logloss: 1.13374\n",
      "[1092]\tvalid_0's multi_logloss: 1.13371\n",
      "[1093]\tvalid_0's multi_logloss: 1.13369\n",
      "[1094]\tvalid_0's multi_logloss: 1.13366\n",
      "[1095]\tvalid_0's multi_logloss: 1.13364\n",
      "[1096]\tvalid_0's multi_logloss: 1.13361\n",
      "[1097]\tvalid_0's multi_logloss: 1.13359\n",
      "[1098]\tvalid_0's multi_logloss: 1.13356\n",
      "[1099]\tvalid_0's multi_logloss: 1.13354\n",
      "[1100]\tvalid_0's multi_logloss: 1.13351\n",
      "[1101]\tvalid_0's multi_logloss: 1.13349\n",
      "[1102]\tvalid_0's multi_logloss: 1.13347\n",
      "[1103]\tvalid_0's multi_logloss: 1.13344\n",
      "[1104]\tvalid_0's multi_logloss: 1.13342\n",
      "[1105]\tvalid_0's multi_logloss: 1.1334\n",
      "[1106]\tvalid_0's multi_logloss: 1.13337\n",
      "[1107]\tvalid_0's multi_logloss: 1.13335\n",
      "[1108]\tvalid_0's multi_logloss: 1.13332\n",
      "[1109]\tvalid_0's multi_logloss: 1.1333\n",
      "[1110]\tvalid_0's multi_logloss: 1.13327\n",
      "[1111]\tvalid_0's multi_logloss: 1.13325\n",
      "[1112]\tvalid_0's multi_logloss: 1.13322\n",
      "[1113]\tvalid_0's multi_logloss: 1.1332\n",
      "[1114]\tvalid_0's multi_logloss: 1.13318\n",
      "[1115]\tvalid_0's multi_logloss: 1.13315\n",
      "[1116]\tvalid_0's multi_logloss: 1.13313\n",
      "[1117]\tvalid_0's multi_logloss: 1.1331\n",
      "[1118]\tvalid_0's multi_logloss: 1.13308\n",
      "[1119]\tvalid_0's multi_logloss: 1.13306\n",
      "[1120]\tvalid_0's multi_logloss: 1.13303\n",
      "[1121]\tvalid_0's multi_logloss: 1.13301\n",
      "[1122]\tvalid_0's multi_logloss: 1.13298\n",
      "[1123]\tvalid_0's multi_logloss: 1.13296\n",
      "[1124]\tvalid_0's multi_logloss: 1.13294\n",
      "[1125]\tvalid_0's multi_logloss: 1.13291\n",
      "[1126]\tvalid_0's multi_logloss: 1.13289\n",
      "[1127]\tvalid_0's multi_logloss: 1.13287\n",
      "[1128]\tvalid_0's multi_logloss: 1.13284\n",
      "[1129]\tvalid_0's multi_logloss: 1.13282\n",
      "[1130]\tvalid_0's multi_logloss: 1.1328\n",
      "[1131]\tvalid_0's multi_logloss: 1.13278\n",
      "[1132]\tvalid_0's multi_logloss: 1.13275\n",
      "[1133]\tvalid_0's multi_logloss: 1.13273\n",
      "[1134]\tvalid_0's multi_logloss: 1.13271\n",
      "[1135]\tvalid_0's multi_logloss: 1.13269\n",
      "[1136]\tvalid_0's multi_logloss: 1.13266\n",
      "[1137]\tvalid_0's multi_logloss: 1.13264\n",
      "[1138]\tvalid_0's multi_logloss: 1.13262\n",
      "[1139]\tvalid_0's multi_logloss: 1.1326\n",
      "[1140]\tvalid_0's multi_logloss: 1.13257\n",
      "[1141]\tvalid_0's multi_logloss: 1.13255\n",
      "[1142]\tvalid_0's multi_logloss: 1.13253\n",
      "[1143]\tvalid_0's multi_logloss: 1.13251\n",
      "[1144]\tvalid_0's multi_logloss: 1.13249\n",
      "[1145]\tvalid_0's multi_logloss: 1.13247\n",
      "[1146]\tvalid_0's multi_logloss: 1.13244\n",
      "[1147]\tvalid_0's multi_logloss: 1.13242\n",
      "[1148]\tvalid_0's multi_logloss: 1.1324\n",
      "[1149]\tvalid_0's multi_logloss: 1.13238\n",
      "[1150]\tvalid_0's multi_logloss: 1.13236\n",
      "[1151]\tvalid_0's multi_logloss: 1.13234\n",
      "[1152]\tvalid_0's multi_logloss: 1.13231\n",
      "[1153]\tvalid_0's multi_logloss: 1.1323\n",
      "[1154]\tvalid_0's multi_logloss: 1.13227\n",
      "[1155]\tvalid_0's multi_logloss: 1.13225\n",
      "[1156]\tvalid_0's multi_logloss: 1.13223\n",
      "[1157]\tvalid_0's multi_logloss: 1.13221\n",
      "[1158]\tvalid_0's multi_logloss: 1.13219\n",
      "[1159]\tvalid_0's multi_logloss: 1.13217\n",
      "[1160]\tvalid_0's multi_logloss: 1.13215\n",
      "[1161]\tvalid_0's multi_logloss: 1.13213\n",
      "[1162]\tvalid_0's multi_logloss: 1.13211\n",
      "[1163]\tvalid_0's multi_logloss: 1.13209\n",
      "[1164]\tvalid_0's multi_logloss: 1.13206\n",
      "[1165]\tvalid_0's multi_logloss: 1.13205\n",
      "[1166]\tvalid_0's multi_logloss: 1.13202\n",
      "[1167]\tvalid_0's multi_logloss: 1.13201\n",
      "[1168]\tvalid_0's multi_logloss: 1.13198\n",
      "[1169]\tvalid_0's multi_logloss: 1.13197\n",
      "[1170]\tvalid_0's multi_logloss: 1.13194\n",
      "[1171]\tvalid_0's multi_logloss: 1.13193\n",
      "[1172]\tvalid_0's multi_logloss: 1.1319\n",
      "[1173]\tvalid_0's multi_logloss: 1.13189\n",
      "[1174]\tvalid_0's multi_logloss: 1.13186\n",
      "[1175]\tvalid_0's multi_logloss: 1.13185\n",
      "[1176]\tvalid_0's multi_logloss: 1.13183\n",
      "[1177]\tvalid_0's multi_logloss: 1.13181\n",
      "[1178]\tvalid_0's multi_logloss: 1.13179\n",
      "[1179]\tvalid_0's multi_logloss: 1.13177\n",
      "[1180]\tvalid_0's multi_logloss: 1.13175\n",
      "[1181]\tvalid_0's multi_logloss: 1.13173\n",
      "[1182]\tvalid_0's multi_logloss: 1.13171\n",
      "[1183]\tvalid_0's multi_logloss: 1.13169\n",
      "[1184]\tvalid_0's multi_logloss: 1.13167\n",
      "[1185]\tvalid_0's multi_logloss: 1.13166\n",
      "[1186]\tvalid_0's multi_logloss: 1.13164\n",
      "[1187]\tvalid_0's multi_logloss: 1.13162\n",
      "[1188]\tvalid_0's multi_logloss: 1.1316\n",
      "[1189]\tvalid_0's multi_logloss: 1.13158\n",
      "[1190]\tvalid_0's multi_logloss: 1.13156\n",
      "[1191]\tvalid_0's multi_logloss: 1.13154\n",
      "[1192]\tvalid_0's multi_logloss: 1.13152\n",
      "[1193]\tvalid_0's multi_logloss: 1.1315\n",
      "[1194]\tvalid_0's multi_logloss: 1.13148\n",
      "[1195]\tvalid_0's multi_logloss: 1.13146\n",
      "[1196]\tvalid_0's multi_logloss: 1.13144\n",
      "[1197]\tvalid_0's multi_logloss: 1.13142\n",
      "[1198]\tvalid_0's multi_logloss: 1.1314\n",
      "[1199]\tvalid_0's multi_logloss: 1.13138\n",
      "[1200]\tvalid_0's multi_logloss: 1.13136\n",
      "[1201]\tvalid_0's multi_logloss: 1.13134\n",
      "[1202]\tvalid_0's multi_logloss: 1.13132\n",
      "[1203]\tvalid_0's multi_logloss: 1.1313\n",
      "[1204]\tvalid_0's multi_logloss: 1.13128\n",
      "[1205]\tvalid_0's multi_logloss: 1.13126\n",
      "[1206]\tvalid_0's multi_logloss: 1.13124\n",
      "[1207]\tvalid_0's multi_logloss: 1.13122\n",
      "[1208]\tvalid_0's multi_logloss: 1.1312\n",
      "[1209]\tvalid_0's multi_logloss: 1.13118\n",
      "[1210]\tvalid_0's multi_logloss: 1.13116\n",
      "[1211]\tvalid_0's multi_logloss: 1.13114\n",
      "[1212]\tvalid_0's multi_logloss: 1.13112\n",
      "[1213]\tvalid_0's multi_logloss: 1.13111\n",
      "[1214]\tvalid_0's multi_logloss: 1.13109\n",
      "[1215]\tvalid_0's multi_logloss: 1.13107\n",
      "[1216]\tvalid_0's multi_logloss: 1.13105\n",
      "[1217]\tvalid_0's multi_logloss: 1.13103\n",
      "[1218]\tvalid_0's multi_logloss: 1.13101\n",
      "[1219]\tvalid_0's multi_logloss: 1.131\n",
      "[1220]\tvalid_0's multi_logloss: 1.13098\n",
      "[1221]\tvalid_0's multi_logloss: 1.13096\n",
      "[1222]\tvalid_0's multi_logloss: 1.13094\n",
      "[1223]\tvalid_0's multi_logloss: 1.13093\n",
      "[1224]\tvalid_0's multi_logloss: 1.13091\n",
      "[1225]\tvalid_0's multi_logloss: 1.13089\n",
      "[1226]\tvalid_0's multi_logloss: 1.13088\n",
      "[1227]\tvalid_0's multi_logloss: 1.13086\n",
      "[1228]\tvalid_0's multi_logloss: 1.13084\n",
      "[1229]\tvalid_0's multi_logloss: 1.13083\n",
      "[1230]\tvalid_0's multi_logloss: 1.13081\n",
      "[1231]\tvalid_0's multi_logloss: 1.13079\n",
      "[1232]\tvalid_0's multi_logloss: 1.13077\n",
      "[1233]\tvalid_0's multi_logloss: 1.13075\n",
      "[1234]\tvalid_0's multi_logloss: 1.13073\n",
      "[1235]\tvalid_0's multi_logloss: 1.13072\n",
      "[1236]\tvalid_0's multi_logloss: 1.13069\n",
      "[1237]\tvalid_0's multi_logloss: 1.13068\n",
      "[1238]\tvalid_0's multi_logloss: 1.13066\n",
      "[1239]\tvalid_0's multi_logloss: 1.13064\n",
      "[1240]\tvalid_0's multi_logloss: 1.13062\n",
      "[1241]\tvalid_0's multi_logloss: 1.13061\n",
      "[1242]\tvalid_0's multi_logloss: 1.13059\n",
      "[1243]\tvalid_0's multi_logloss: 1.13057\n",
      "[1244]\tvalid_0's multi_logloss: 1.13055\n",
      "[1245]\tvalid_0's multi_logloss: 1.13053\n",
      "[1246]\tvalid_0's multi_logloss: 1.13051\n",
      "[1247]\tvalid_0's multi_logloss: 1.1305\n",
      "[1248]\tvalid_0's multi_logloss: 1.13048\n",
      "[1249]\tvalid_0's multi_logloss: 1.13046\n",
      "[1250]\tvalid_0's multi_logloss: 1.13044\n",
      "[1251]\tvalid_0's multi_logloss: 1.13043\n",
      "[1252]\tvalid_0's multi_logloss: 1.13041\n",
      "[1253]\tvalid_0's multi_logloss: 1.13039\n",
      "[1254]\tvalid_0's multi_logloss: 1.13037\n",
      "[1255]\tvalid_0's multi_logloss: 1.13036\n",
      "[1256]\tvalid_0's multi_logloss: 1.13034\n",
      "[1257]\tvalid_0's multi_logloss: 1.13032\n",
      "[1258]\tvalid_0's multi_logloss: 1.1303\n",
      "[1259]\tvalid_0's multi_logloss: 1.13029\n",
      "[1260]\tvalid_0's multi_logloss: 1.13027\n",
      "[1261]\tvalid_0's multi_logloss: 1.13025\n",
      "[1262]\tvalid_0's multi_logloss: 1.13024\n",
      "[1263]\tvalid_0's multi_logloss: 1.13022\n",
      "[1264]\tvalid_0's multi_logloss: 1.1302\n",
      "[1265]\tvalid_0's multi_logloss: 1.13019\n",
      "[1266]\tvalid_0's multi_logloss: 1.13017\n",
      "[1267]\tvalid_0's multi_logloss: 1.13016\n",
      "[1268]\tvalid_0's multi_logloss: 1.13014\n",
      "[1269]\tvalid_0's multi_logloss: 1.13013\n",
      "[1270]\tvalid_0's multi_logloss: 1.13011\n",
      "[1271]\tvalid_0's multi_logloss: 1.13009\n",
      "[1272]\tvalid_0's multi_logloss: 1.13008\n",
      "[1273]\tvalid_0's multi_logloss: 1.13006\n",
      "[1274]\tvalid_0's multi_logloss: 1.13005\n",
      "[1275]\tvalid_0's multi_logloss: 1.13003\n",
      "[1276]\tvalid_0's multi_logloss: 1.13001\n",
      "[1277]\tvalid_0's multi_logloss: 1.13\n",
      "[1278]\tvalid_0's multi_logloss: 1.12998\n",
      "[1279]\tvalid_0's multi_logloss: 1.12997\n",
      "[1280]\tvalid_0's multi_logloss: 1.12995\n",
      "[1281]\tvalid_0's multi_logloss: 1.12994\n",
      "[1282]\tvalid_0's multi_logloss: 1.12992\n",
      "[1283]\tvalid_0's multi_logloss: 1.12991\n",
      "[1284]\tvalid_0's multi_logloss: 1.12989\n",
      "[1285]\tvalid_0's multi_logloss: 1.12988\n",
      "[1286]\tvalid_0's multi_logloss: 1.12986\n",
      "[1287]\tvalid_0's multi_logloss: 1.12985\n",
      "[1288]\tvalid_0's multi_logloss: 1.12984\n",
      "[1289]\tvalid_0's multi_logloss: 1.12982\n",
      "[1290]\tvalid_0's multi_logloss: 1.12981\n",
      "[1291]\tvalid_0's multi_logloss: 1.12979\n",
      "[1292]\tvalid_0's multi_logloss: 1.12977\n",
      "[1293]\tvalid_0's multi_logloss: 1.12976\n",
      "[1294]\tvalid_0's multi_logloss: 1.12974\n",
      "[1295]\tvalid_0's multi_logloss: 1.12972\n",
      "[1296]\tvalid_0's multi_logloss: 1.1297\n",
      "[1297]\tvalid_0's multi_logloss: 1.12969\n",
      "[1298]\tvalid_0's multi_logloss: 1.12967\n",
      "[1299]\tvalid_0's multi_logloss: 1.12966\n",
      "[1300]\tvalid_0's multi_logloss: 1.12964\n",
      "[1301]\tvalid_0's multi_logloss: 1.12962\n",
      "[1302]\tvalid_0's multi_logloss: 1.1296\n",
      "[1303]\tvalid_0's multi_logloss: 1.12959\n",
      "[1304]\tvalid_0's multi_logloss: 1.12957\n",
      "[1305]\tvalid_0's multi_logloss: 1.12956\n",
      "[1306]\tvalid_0's multi_logloss: 1.12954\n",
      "[1307]\tvalid_0's multi_logloss: 1.12953\n",
      "[1308]\tvalid_0's multi_logloss: 1.12951\n",
      "[1309]\tvalid_0's multi_logloss: 1.1295\n",
      "[1310]\tvalid_0's multi_logloss: 1.12948\n",
      "[1311]\tvalid_0's multi_logloss: 1.12947\n",
      "[1312]\tvalid_0's multi_logloss: 1.12945\n",
      "[1313]\tvalid_0's multi_logloss: 1.12943\n",
      "[1314]\tvalid_0's multi_logloss: 1.12942\n",
      "[1315]\tvalid_0's multi_logloss: 1.1294\n",
      "[1316]\tvalid_0's multi_logloss: 1.12939\n",
      "[1317]\tvalid_0's multi_logloss: 1.12937\n",
      "[1318]\tvalid_0's multi_logloss: 1.12936\n",
      "[1319]\tvalid_0's multi_logloss: 1.12934\n",
      "[1320]\tvalid_0's multi_logloss: 1.12933\n",
      "[1321]\tvalid_0's multi_logloss: 1.12931\n",
      "[1322]\tvalid_0's multi_logloss: 1.1293\n",
      "[1323]\tvalid_0's multi_logloss: 1.12929\n",
      "[1324]\tvalid_0's multi_logloss: 1.12927\n",
      "[1325]\tvalid_0's multi_logloss: 1.12926\n",
      "[1326]\tvalid_0's multi_logloss: 1.12924\n",
      "[1327]\tvalid_0's multi_logloss: 1.12923\n",
      "[1328]\tvalid_0's multi_logloss: 1.12921\n",
      "[1329]\tvalid_0's multi_logloss: 1.1292\n",
      "[1330]\tvalid_0's multi_logloss: 1.12918\n",
      "[1331]\tvalid_0's multi_logloss: 1.12917\n",
      "[1332]\tvalid_0's multi_logloss: 1.12916\n",
      "[1333]\tvalid_0's multi_logloss: 1.12914\n",
      "[1334]\tvalid_0's multi_logloss: 1.12913\n",
      "[1335]\tvalid_0's multi_logloss: 1.12911\n",
      "[1336]\tvalid_0's multi_logloss: 1.1291\n",
      "[1337]\tvalid_0's multi_logloss: 1.12909\n",
      "[1338]\tvalid_0's multi_logloss: 1.12907\n",
      "[1339]\tvalid_0's multi_logloss: 1.12906\n",
      "[1340]\tvalid_0's multi_logloss: 1.12904\n",
      "[1341]\tvalid_0's multi_logloss: 1.12903\n",
      "[1342]\tvalid_0's multi_logloss: 1.12902\n",
      "[1343]\tvalid_0's multi_logloss: 1.129\n",
      "[1344]\tvalid_0's multi_logloss: 1.12899\n",
      "[1345]\tvalid_0's multi_logloss: 1.12898\n",
      "[1346]\tvalid_0's multi_logloss: 1.12896\n",
      "[1347]\tvalid_0's multi_logloss: 1.12895\n",
      "[1348]\tvalid_0's multi_logloss: 1.12894\n",
      "[1349]\tvalid_0's multi_logloss: 1.12892\n",
      "[1350]\tvalid_0's multi_logloss: 1.12891\n",
      "[1351]\tvalid_0's multi_logloss: 1.1289\n",
      "[1352]\tvalid_0's multi_logloss: 1.12888\n",
      "[1353]\tvalid_0's multi_logloss: 1.12887\n",
      "[1354]\tvalid_0's multi_logloss: 1.12885\n",
      "[1355]\tvalid_0's multi_logloss: 1.12884\n",
      "[1356]\tvalid_0's multi_logloss: 1.12883\n",
      "[1357]\tvalid_0's multi_logloss: 1.12881\n",
      "[1358]\tvalid_0's multi_logloss: 1.1288\n",
      "[1359]\tvalid_0's multi_logloss: 1.12879\n",
      "[1360]\tvalid_0's multi_logloss: 1.12877\n",
      "[1361]\tvalid_0's multi_logloss: 1.12876\n",
      "[1362]\tvalid_0's multi_logloss: 1.12875\n",
      "[1363]\tvalid_0's multi_logloss: 1.12873\n",
      "[1364]\tvalid_0's multi_logloss: 1.12872\n",
      "[1365]\tvalid_0's multi_logloss: 1.12871\n",
      "[1366]\tvalid_0's multi_logloss: 1.12869\n",
      "[1367]\tvalid_0's multi_logloss: 1.12868\n",
      "[1368]\tvalid_0's multi_logloss: 1.12867\n",
      "[1369]\tvalid_0's multi_logloss: 1.12865\n",
      "[1370]\tvalid_0's multi_logloss: 1.12864\n",
      "[1371]\tvalid_0's multi_logloss: 1.12863\n",
      "[1372]\tvalid_0's multi_logloss: 1.12861\n",
      "[1373]\tvalid_0's multi_logloss: 1.1286\n",
      "[1374]\tvalid_0's multi_logloss: 1.12859\n",
      "[1375]\tvalid_0's multi_logloss: 1.12858\n",
      "[1376]\tvalid_0's multi_logloss: 1.12856\n",
      "[1377]\tvalid_0's multi_logloss: 1.12855\n",
      "[1378]\tvalid_0's multi_logloss: 1.12854\n",
      "[1379]\tvalid_0's multi_logloss: 1.12852\n",
      "[1380]\tvalid_0's multi_logloss: 1.12851\n",
      "[1381]\tvalid_0's multi_logloss: 1.1285\n",
      "[1382]\tvalid_0's multi_logloss: 1.12848\n",
      "[1383]\tvalid_0's multi_logloss: 1.12847\n",
      "[1384]\tvalid_0's multi_logloss: 1.12846\n",
      "[1385]\tvalid_0's multi_logloss: 1.12845\n",
      "[1386]\tvalid_0's multi_logloss: 1.12843\n",
      "[1387]\tvalid_0's multi_logloss: 1.12842\n",
      "[1388]\tvalid_0's multi_logloss: 1.12841\n",
      "[1389]\tvalid_0's multi_logloss: 1.1284\n",
      "[1390]\tvalid_0's multi_logloss: 1.12838\n",
      "[1391]\tvalid_0's multi_logloss: 1.12837\n",
      "[1392]\tvalid_0's multi_logloss: 1.12836\n",
      "[1393]\tvalid_0's multi_logloss: 1.12835\n",
      "[1394]\tvalid_0's multi_logloss: 1.12833\n",
      "[1395]\tvalid_0's multi_logloss: 1.12832\n",
      "[1396]\tvalid_0's multi_logloss: 1.12831\n",
      "[1397]\tvalid_0's multi_logloss: 1.1283\n",
      "[1398]\tvalid_0's multi_logloss: 1.12829\n",
      "[1399]\tvalid_0's multi_logloss: 1.12827\n",
      "[1400]\tvalid_0's multi_logloss: 1.12826\n",
      "[1401]\tvalid_0's multi_logloss: 1.12825\n",
      "[1402]\tvalid_0's multi_logloss: 1.12824\n",
      "[1403]\tvalid_0's multi_logloss: 1.12823\n",
      "[1404]\tvalid_0's multi_logloss: 1.12821\n",
      "[1405]\tvalid_0's multi_logloss: 1.1282\n",
      "[1406]\tvalid_0's multi_logloss: 1.12819\n",
      "[1407]\tvalid_0's multi_logloss: 1.12818\n",
      "[1408]\tvalid_0's multi_logloss: 1.12816\n",
      "[1409]\tvalid_0's multi_logloss: 1.12815\n",
      "[1410]\tvalid_0's multi_logloss: 1.12814\n",
      "[1411]\tvalid_0's multi_logloss: 1.12813\n",
      "[1412]\tvalid_0's multi_logloss: 1.12812\n",
      "[1413]\tvalid_0's multi_logloss: 1.12811\n",
      "[1414]\tvalid_0's multi_logloss: 1.12809\n",
      "[1415]\tvalid_0's multi_logloss: 1.12808\n",
      "[1416]\tvalid_0's multi_logloss: 1.12807\n",
      "[1417]\tvalid_0's multi_logloss: 1.12806\n",
      "[1418]\tvalid_0's multi_logloss: 1.12805\n",
      "[1419]\tvalid_0's multi_logloss: 1.12804\n",
      "[1420]\tvalid_0's multi_logloss: 1.12802\n",
      "[1421]\tvalid_0's multi_logloss: 1.12801\n",
      "[1422]\tvalid_0's multi_logloss: 1.128\n",
      "[1423]\tvalid_0's multi_logloss: 1.12799\n",
      "[1424]\tvalid_0's multi_logloss: 1.12798\n",
      "[1425]\tvalid_0's multi_logloss: 1.12797\n",
      "[1426]\tvalid_0's multi_logloss: 1.12796\n",
      "[1427]\tvalid_0's multi_logloss: 1.12795\n",
      "[1428]\tvalid_0's multi_logloss: 1.12793\n",
      "[1429]\tvalid_0's multi_logloss: 1.12792\n",
      "[1430]\tvalid_0's multi_logloss: 1.12791\n",
      "[1431]\tvalid_0's multi_logloss: 1.1279\n",
      "[1432]\tvalid_0's multi_logloss: 1.12789\n",
      "[1433]\tvalid_0's multi_logloss: 1.12788\n",
      "[1434]\tvalid_0's multi_logloss: 1.12787\n",
      "[1435]\tvalid_0's multi_logloss: 1.12786\n",
      "[1436]\tvalid_0's multi_logloss: 1.12785\n",
      "[1437]\tvalid_0's multi_logloss: 1.12784\n",
      "[1438]\tvalid_0's multi_logloss: 1.12782\n",
      "[1439]\tvalid_0's multi_logloss: 1.12781\n",
      "[1440]\tvalid_0's multi_logloss: 1.1278\n",
      "[1441]\tvalid_0's multi_logloss: 1.12779\n",
      "[1442]\tvalid_0's multi_logloss: 1.12778\n",
      "[1443]\tvalid_0's multi_logloss: 1.12777\n",
      "[1444]\tvalid_0's multi_logloss: 1.12776\n",
      "[1445]\tvalid_0's multi_logloss: 1.12775\n",
      "[1446]\tvalid_0's multi_logloss: 1.12774\n",
      "[1447]\tvalid_0's multi_logloss: 1.12773\n",
      "[1448]\tvalid_0's multi_logloss: 1.12772\n",
      "[1449]\tvalid_0's multi_logloss: 1.12771\n",
      "[1450]\tvalid_0's multi_logloss: 1.12769\n",
      "[1451]\tvalid_0's multi_logloss: 1.12768\n",
      "[1452]\tvalid_0's multi_logloss: 1.12767\n",
      "[1453]\tvalid_0's multi_logloss: 1.12766\n",
      "[1454]\tvalid_0's multi_logloss: 1.12765\n",
      "[1455]\tvalid_0's multi_logloss: 1.12764\n",
      "[1456]\tvalid_0's multi_logloss: 1.12763\n",
      "[1457]\tvalid_0's multi_logloss: 1.12762\n",
      "[1458]\tvalid_0's multi_logloss: 1.12761\n",
      "[1459]\tvalid_0's multi_logloss: 1.1276\n",
      "[1460]\tvalid_0's multi_logloss: 1.12759\n",
      "[1461]\tvalid_0's multi_logloss: 1.12758\n",
      "[1462]\tvalid_0's multi_logloss: 1.12757\n",
      "[1463]\tvalid_0's multi_logloss: 1.12756\n",
      "[1464]\tvalid_0's multi_logloss: 1.12755\n",
      "[1465]\tvalid_0's multi_logloss: 1.12754\n",
      "[1466]\tvalid_0's multi_logloss: 1.12753\n",
      "[1467]\tvalid_0's multi_logloss: 1.12752\n",
      "[1468]\tvalid_0's multi_logloss: 1.12751\n",
      "[1469]\tvalid_0's multi_logloss: 1.1275\n",
      "[1470]\tvalid_0's multi_logloss: 1.12749\n",
      "[1471]\tvalid_0's multi_logloss: 1.12748\n",
      "[1472]\tvalid_0's multi_logloss: 1.12747\n",
      "[1473]\tvalid_0's multi_logloss: 1.12746\n",
      "[1474]\tvalid_0's multi_logloss: 1.12745\n",
      "[1475]\tvalid_0's multi_logloss: 1.12744\n",
      "[1476]\tvalid_0's multi_logloss: 1.12742\n",
      "[1477]\tvalid_0's multi_logloss: 1.12741\n",
      "[1478]\tvalid_0's multi_logloss: 1.1274\n",
      "[1479]\tvalid_0's multi_logloss: 1.12739\n",
      "[1480]\tvalid_0's multi_logloss: 1.12738\n",
      "[1481]\tvalid_0's multi_logloss: 1.12737\n",
      "[1482]\tvalid_0's multi_logloss: 1.12735\n",
      "[1483]\tvalid_0's multi_logloss: 1.12735\n",
      "[1484]\tvalid_0's multi_logloss: 1.12733\n",
      "[1485]\tvalid_0's multi_logloss: 1.12732\n",
      "[1486]\tvalid_0's multi_logloss: 1.12731\n",
      "[1487]\tvalid_0's multi_logloss: 1.1273\n",
      "[1488]\tvalid_0's multi_logloss: 1.12729\n",
      "[1489]\tvalid_0's multi_logloss: 1.12728\n",
      "[1490]\tvalid_0's multi_logloss: 1.12727\n",
      "[1491]\tvalid_0's multi_logloss: 1.12726\n",
      "[1492]\tvalid_0's multi_logloss: 1.12725\n",
      "[1493]\tvalid_0's multi_logloss: 1.12724\n",
      "[1494]\tvalid_0's multi_logloss: 1.12723\n",
      "[1495]\tvalid_0's multi_logloss: 1.12722\n",
      "[1496]\tvalid_0's multi_logloss: 1.12721\n",
      "[1497]\tvalid_0's multi_logloss: 1.1272\n",
      "[1498]\tvalid_0's multi_logloss: 1.12719\n",
      "[1499]\tvalid_0's multi_logloss: 1.12719\n",
      "[1500]\tvalid_0's multi_logloss: 1.12718\n",
      "[1501]\tvalid_0's multi_logloss: 1.12717\n",
      "[1502]\tvalid_0's multi_logloss: 1.12716\n",
      "[1503]\tvalid_0's multi_logloss: 1.12715\n",
      "[1504]\tvalid_0's multi_logloss: 1.12714\n",
      "[1505]\tvalid_0's multi_logloss: 1.12713\n",
      "[1506]\tvalid_0's multi_logloss: 1.12712\n",
      "[1507]\tvalid_0's multi_logloss: 1.12711\n",
      "[1508]\tvalid_0's multi_logloss: 1.1271\n",
      "[1509]\tvalid_0's multi_logloss: 1.12709\n",
      "[1510]\tvalid_0's multi_logloss: 1.12708\n",
      "[1511]\tvalid_0's multi_logloss: 1.12708\n",
      "[1512]\tvalid_0's multi_logloss: 1.12707\n",
      "[1513]\tvalid_0's multi_logloss: 1.12706\n",
      "[1514]\tvalid_0's multi_logloss: 1.12705\n",
      "[1515]\tvalid_0's multi_logloss: 1.12704\n",
      "[1516]\tvalid_0's multi_logloss: 1.12703\n",
      "[1517]\tvalid_0's multi_logloss: 1.12702\n",
      "[1518]\tvalid_0's multi_logloss: 1.12701\n",
      "[1519]\tvalid_0's multi_logloss: 1.12701\n",
      "[1520]\tvalid_0's multi_logloss: 1.127\n",
      "[1521]\tvalid_0's multi_logloss: 1.12699\n",
      "[1522]\tvalid_0's multi_logloss: 1.12698\n",
      "[1523]\tvalid_0's multi_logloss: 1.12697\n",
      "[1524]\tvalid_0's multi_logloss: 1.12696\n",
      "[1525]\tvalid_0's multi_logloss: 1.12696\n",
      "[1526]\tvalid_0's multi_logloss: 1.12695\n",
      "[1527]\tvalid_0's multi_logloss: 1.12694\n",
      "[1528]\tvalid_0's multi_logloss: 1.12693\n",
      "[1529]\tvalid_0's multi_logloss: 1.12692\n",
      "[1530]\tvalid_0's multi_logloss: 1.12691\n",
      "[1531]\tvalid_0's multi_logloss: 1.1269\n",
      "[1532]\tvalid_0's multi_logloss: 1.12689\n",
      "[1533]\tvalid_0's multi_logloss: 1.12689\n",
      "[1534]\tvalid_0's multi_logloss: 1.12687\n",
      "[1535]\tvalid_0's multi_logloss: 1.12687\n",
      "[1536]\tvalid_0's multi_logloss: 1.12686\n",
      "[1537]\tvalid_0's multi_logloss: 1.12685\n",
      "[1538]\tvalid_0's multi_logloss: 1.12684\n",
      "[1539]\tvalid_0's multi_logloss: 1.12683\n",
      "[1540]\tvalid_0's multi_logloss: 1.12682\n",
      "[1541]\tvalid_0's multi_logloss: 1.12682\n",
      "[1542]\tvalid_0's multi_logloss: 1.12681\n",
      "[1543]\tvalid_0's multi_logloss: 1.1268\n",
      "[1544]\tvalid_0's multi_logloss: 1.12679\n",
      "[1545]\tvalid_0's multi_logloss: 1.12678\n",
      "[1546]\tvalid_0's multi_logloss: 1.12677\n",
      "[1547]\tvalid_0's multi_logloss: 1.12677\n",
      "[1548]\tvalid_0's multi_logloss: 1.12676\n",
      "[1549]\tvalid_0's multi_logloss: 1.12675\n",
      "[1550]\tvalid_0's multi_logloss: 1.12674\n",
      "[1551]\tvalid_0's multi_logloss: 1.12673\n",
      "[1552]\tvalid_0's multi_logloss: 1.12672\n",
      "[1553]\tvalid_0's multi_logloss: 1.12672\n",
      "[1554]\tvalid_0's multi_logloss: 1.12671\n",
      "[1555]\tvalid_0's multi_logloss: 1.1267\n",
      "[1556]\tvalid_0's multi_logloss: 1.12669\n",
      "[1557]\tvalid_0's multi_logloss: 1.12669\n",
      "[1558]\tvalid_0's multi_logloss: 1.12668\n",
      "[1559]\tvalid_0's multi_logloss: 1.12667\n",
      "[1560]\tvalid_0's multi_logloss: 1.12666\n",
      "[1561]\tvalid_0's multi_logloss: 1.12665\n",
      "[1562]\tvalid_0's multi_logloss: 1.12664\n",
      "[1563]\tvalid_0's multi_logloss: 1.12664\n",
      "[1564]\tvalid_0's multi_logloss: 1.12662\n",
      "[1565]\tvalid_0's multi_logloss: 1.12662\n",
      "[1566]\tvalid_0's multi_logloss: 1.12661\n",
      "[1567]\tvalid_0's multi_logloss: 1.1266\n",
      "[1568]\tvalid_0's multi_logloss: 1.12659\n",
      "[1569]\tvalid_0's multi_logloss: 1.12658\n",
      "[1570]\tvalid_0's multi_logloss: 1.12657\n",
      "[1571]\tvalid_0's multi_logloss: 1.12656\n",
      "[1572]\tvalid_0's multi_logloss: 1.12655\n",
      "[1573]\tvalid_0's multi_logloss: 1.12655\n",
      "[1574]\tvalid_0's multi_logloss: 1.12654\n",
      "[1575]\tvalid_0's multi_logloss: 1.12653\n",
      "[1576]\tvalid_0's multi_logloss: 1.12652\n",
      "[1577]\tvalid_0's multi_logloss: 1.12651\n",
      "[1578]\tvalid_0's multi_logloss: 1.1265\n",
      "[1579]\tvalid_0's multi_logloss: 1.1265\n",
      "[1580]\tvalid_0's multi_logloss: 1.12649\n",
      "[1581]\tvalid_0's multi_logloss: 1.12648\n",
      "[1582]\tvalid_0's multi_logloss: 1.12647\n",
      "[1583]\tvalid_0's multi_logloss: 1.12647\n",
      "[1584]\tvalid_0's multi_logloss: 1.12646\n",
      "[1585]\tvalid_0's multi_logloss: 1.12645\n",
      "[1586]\tvalid_0's multi_logloss: 1.12644\n",
      "[1587]\tvalid_0's multi_logloss: 1.12644\n",
      "[1588]\tvalid_0's multi_logloss: 1.12642\n",
      "[1589]\tvalid_0's multi_logloss: 1.12642\n",
      "[1590]\tvalid_0's multi_logloss: 1.12641\n",
      "[1591]\tvalid_0's multi_logloss: 1.1264\n",
      "[1592]\tvalid_0's multi_logloss: 1.12639\n",
      "[1593]\tvalid_0's multi_logloss: 1.12638\n",
      "[1594]\tvalid_0's multi_logloss: 1.12637\n",
      "[1595]\tvalid_0's multi_logloss: 1.12637\n",
      "[1596]\tvalid_0's multi_logloss: 1.12635\n",
      "[1597]\tvalid_0's multi_logloss: 1.12635\n",
      "[1598]\tvalid_0's multi_logloss: 1.12634\n",
      "[1599]\tvalid_0's multi_logloss: 1.12633\n",
      "[1600]\tvalid_0's multi_logloss: 1.12632\n",
      "[1601]\tvalid_0's multi_logloss: 1.12631\n",
      "[1602]\tvalid_0's multi_logloss: 1.1263\n",
      "[1603]\tvalid_0's multi_logloss: 1.12629\n",
      "[1604]\tvalid_0's multi_logloss: 1.12628\n",
      "[1605]\tvalid_0's multi_logloss: 1.12627\n",
      "[1606]\tvalid_0's multi_logloss: 1.12626\n",
      "[1607]\tvalid_0's multi_logloss: 1.12626\n",
      "[1608]\tvalid_0's multi_logloss: 1.12625\n",
      "[1609]\tvalid_0's multi_logloss: 1.12624\n",
      "[1610]\tvalid_0's multi_logloss: 1.12623\n",
      "[1611]\tvalid_0's multi_logloss: 1.12622\n",
      "[1612]\tvalid_0's multi_logloss: 1.12621\n",
      "[1613]\tvalid_0's multi_logloss: 1.12621\n",
      "[1614]\tvalid_0's multi_logloss: 1.1262\n",
      "[1615]\tvalid_0's multi_logloss: 1.12619\n",
      "[1616]\tvalid_0's multi_logloss: 1.12618\n",
      "[1617]\tvalid_0's multi_logloss: 1.12617\n",
      "[1618]\tvalid_0's multi_logloss: 1.12616\n",
      "[1619]\tvalid_0's multi_logloss: 1.12616\n",
      "[1620]\tvalid_0's multi_logloss: 1.12615\n",
      "[1621]\tvalid_0's multi_logloss: 1.12614\n",
      "[1622]\tvalid_0's multi_logloss: 1.12613\n",
      "[1623]\tvalid_0's multi_logloss: 1.12613\n",
      "[1624]\tvalid_0's multi_logloss: 1.12612\n",
      "[1625]\tvalid_0's multi_logloss: 1.12611\n",
      "[1626]\tvalid_0's multi_logloss: 1.1261\n",
      "[1627]\tvalid_0's multi_logloss: 1.1261\n",
      "[1628]\tvalid_0's multi_logloss: 1.12609\n",
      "[1629]\tvalid_0's multi_logloss: 1.12608\n",
      "[1630]\tvalid_0's multi_logloss: 1.12607\n",
      "[1631]\tvalid_0's multi_logloss: 1.12607\n",
      "[1632]\tvalid_0's multi_logloss: 1.12606\n",
      "[1633]\tvalid_0's multi_logloss: 1.12605\n",
      "[1634]\tvalid_0's multi_logloss: 1.12605\n",
      "[1635]\tvalid_0's multi_logloss: 1.12604\n",
      "[1636]\tvalid_0's multi_logloss: 1.12603\n",
      "[1637]\tvalid_0's multi_logloss: 1.12603\n",
      "[1638]\tvalid_0's multi_logloss: 1.12602\n",
      "[1639]\tvalid_0's multi_logloss: 1.12601\n",
      "[1640]\tvalid_0's multi_logloss: 1.12601\n",
      "[1641]\tvalid_0's multi_logloss: 1.126\n",
      "[1642]\tvalid_0's multi_logloss: 1.12599\n",
      "[1643]\tvalid_0's multi_logloss: 1.12599\n",
      "[1644]\tvalid_0's multi_logloss: 1.12598\n",
      "[1645]\tvalid_0's multi_logloss: 1.12597\n",
      "[1646]\tvalid_0's multi_logloss: 1.12597\n",
      "[1647]\tvalid_0's multi_logloss: 1.12596\n",
      "[1648]\tvalid_0's multi_logloss: 1.12595\n",
      "[1649]\tvalid_0's multi_logloss: 1.12595\n",
      "[1650]\tvalid_0's multi_logloss: 1.12594\n",
      "[1651]\tvalid_0's multi_logloss: 1.12594\n",
      "[1652]\tvalid_0's multi_logloss: 1.12593\n",
      "[1653]\tvalid_0's multi_logloss: 1.12592\n",
      "[1654]\tvalid_0's multi_logloss: 1.12591\n",
      "[1655]\tvalid_0's multi_logloss: 1.12591\n",
      "[1656]\tvalid_0's multi_logloss: 1.1259\n",
      "[1657]\tvalid_0's multi_logloss: 1.12589\n",
      "[1658]\tvalid_0's multi_logloss: 1.12588\n",
      "[1659]\tvalid_0's multi_logloss: 1.12588\n",
      "[1660]\tvalid_0's multi_logloss: 1.12587\n",
      "[1661]\tvalid_0's multi_logloss: 1.12586\n",
      "[1662]\tvalid_0's multi_logloss: 1.12586\n",
      "[1663]\tvalid_0's multi_logloss: 1.12585\n",
      "[1664]\tvalid_0's multi_logloss: 1.12584\n",
      "[1665]\tvalid_0's multi_logloss: 1.12584\n",
      "[1666]\tvalid_0's multi_logloss: 1.12583\n",
      "[1667]\tvalid_0's multi_logloss: 1.12582\n",
      "[1668]\tvalid_0's multi_logloss: 1.12582\n",
      "[1669]\tvalid_0's multi_logloss: 1.12581\n",
      "[1670]\tvalid_0's multi_logloss: 1.1258\n",
      "[1671]\tvalid_0's multi_logloss: 1.1258\n",
      "[1672]\tvalid_0's multi_logloss: 1.12579\n",
      "[1673]\tvalid_0's multi_logloss: 1.12579\n",
      "[1674]\tvalid_0's multi_logloss: 1.12578\n",
      "[1675]\tvalid_0's multi_logloss: 1.12577\n",
      "[1676]\tvalid_0's multi_logloss: 1.12577\n",
      "[1677]\tvalid_0's multi_logloss: 1.12576\n",
      "[1678]\tvalid_0's multi_logloss: 1.12576\n",
      "[1679]\tvalid_0's multi_logloss: 1.12575\n",
      "[1680]\tvalid_0's multi_logloss: 1.12574\n",
      "[1681]\tvalid_0's multi_logloss: 1.12574\n",
      "[1682]\tvalid_0's multi_logloss: 1.12573\n",
      "[1683]\tvalid_0's multi_logloss: 1.12573\n",
      "[1684]\tvalid_0's multi_logloss: 1.12572\n",
      "[1685]\tvalid_0's multi_logloss: 1.12572\n",
      "[1686]\tvalid_0's multi_logloss: 1.12571\n",
      "[1687]\tvalid_0's multi_logloss: 1.1257\n",
      "[1688]\tvalid_0's multi_logloss: 1.1257\n",
      "[1689]\tvalid_0's multi_logloss: 1.12569\n",
      "[1690]\tvalid_0's multi_logloss: 1.12569\n",
      "[1691]\tvalid_0's multi_logloss: 1.12568\n",
      "[1692]\tvalid_0's multi_logloss: 1.12567\n",
      "[1693]\tvalid_0's multi_logloss: 1.12567\n",
      "[1694]\tvalid_0's multi_logloss: 1.12566\n",
      "[1695]\tvalid_0's multi_logloss: 1.12566\n",
      "[1696]\tvalid_0's multi_logloss: 1.12565\n",
      "[1697]\tvalid_0's multi_logloss: 1.12565\n",
      "[1698]\tvalid_0's multi_logloss: 1.12564\n",
      "[1699]\tvalid_0's multi_logloss: 1.12563\n",
      "[1700]\tvalid_0's multi_logloss: 1.12563\n",
      "[1701]\tvalid_0's multi_logloss: 1.12562\n",
      "[1702]\tvalid_0's multi_logloss: 1.12562\n",
      "[1703]\tvalid_0's multi_logloss: 1.12561\n",
      "[1704]\tvalid_0's multi_logloss: 1.1256\n",
      "[1705]\tvalid_0's multi_logloss: 1.1256\n",
      "[1706]\tvalid_0's multi_logloss: 1.12559\n",
      "[1707]\tvalid_0's multi_logloss: 1.12559\n",
      "[1708]\tvalid_0's multi_logloss: 1.12558\n",
      "[1709]\tvalid_0's multi_logloss: 1.12558\n",
      "[1710]\tvalid_0's multi_logloss: 1.12557\n",
      "[1711]\tvalid_0's multi_logloss: 1.12556\n",
      "[1712]\tvalid_0's multi_logloss: 1.12556\n",
      "[1713]\tvalid_0's multi_logloss: 1.12555\n",
      "[1714]\tvalid_0's multi_logloss: 1.12555\n",
      "[1715]\tvalid_0's multi_logloss: 1.12554\n",
      "[1716]\tvalid_0's multi_logloss: 1.12553\n",
      "[1717]\tvalid_0's multi_logloss: 1.12553\n",
      "[1718]\tvalid_0's multi_logloss: 1.12552\n",
      "[1719]\tvalid_0's multi_logloss: 1.12552\n",
      "[1720]\tvalid_0's multi_logloss: 1.12551\n",
      "[1721]\tvalid_0's multi_logloss: 1.12551\n",
      "[1722]\tvalid_0's multi_logloss: 1.1255\n",
      "[1723]\tvalid_0's multi_logloss: 1.12549\n",
      "[1724]\tvalid_0's multi_logloss: 1.12549\n",
      "[1725]\tvalid_0's multi_logloss: 1.12548\n",
      "[1726]\tvalid_0's multi_logloss: 1.12548\n",
      "[1727]\tvalid_0's multi_logloss: 1.12547\n",
      "[1728]\tvalid_0's multi_logloss: 1.12546\n",
      "[1729]\tvalid_0's multi_logloss: 1.12546\n",
      "[1730]\tvalid_0's multi_logloss: 1.12545\n",
      "[1731]\tvalid_0's multi_logloss: 1.12544\n",
      "[1732]\tvalid_0's multi_logloss: 1.12544\n",
      "[1733]\tvalid_0's multi_logloss: 1.12543\n",
      "[1734]\tvalid_0's multi_logloss: 1.12542\n",
      "[1735]\tvalid_0's multi_logloss: 1.12542\n",
      "[1736]\tvalid_0's multi_logloss: 1.12541\n",
      "[1737]\tvalid_0's multi_logloss: 1.1254\n",
      "[1738]\tvalid_0's multi_logloss: 1.1254\n",
      "[1739]\tvalid_0's multi_logloss: 1.12539\n",
      "[1740]\tvalid_0's multi_logloss: 1.12539\n",
      "[1741]\tvalid_0's multi_logloss: 1.12538\n",
      "[1742]\tvalid_0's multi_logloss: 1.12537\n",
      "[1743]\tvalid_0's multi_logloss: 1.12537\n",
      "[1744]\tvalid_0's multi_logloss: 1.12536\n",
      "[1745]\tvalid_0's multi_logloss: 1.12536\n",
      "[1746]\tvalid_0's multi_logloss: 1.12535\n",
      "[1747]\tvalid_0's multi_logloss: 1.12535\n",
      "[1748]\tvalid_0's multi_logloss: 1.12534\n",
      "[1749]\tvalid_0's multi_logloss: 1.12534\n",
      "[1750]\tvalid_0's multi_logloss: 1.12533\n",
      "[1751]\tvalid_0's multi_logloss: 1.12533\n",
      "[1752]\tvalid_0's multi_logloss: 1.12532\n",
      "[1753]\tvalid_0's multi_logloss: 1.12531\n",
      "[1754]\tvalid_0's multi_logloss: 1.12531\n",
      "[1755]\tvalid_0's multi_logloss: 1.1253\n",
      "[1756]\tvalid_0's multi_logloss: 1.1253\n",
      "[1757]\tvalid_0's multi_logloss: 1.12529\n",
      "[1758]\tvalid_0's multi_logloss: 1.12528\n",
      "[1759]\tvalid_0's multi_logloss: 1.12528\n",
      "[1760]\tvalid_0's multi_logloss: 1.12527\n",
      "[1761]\tvalid_0's multi_logloss: 1.12527\n",
      "[1762]\tvalid_0's multi_logloss: 1.12526\n",
      "[1763]\tvalid_0's multi_logloss: 1.12526\n",
      "[1764]\tvalid_0's multi_logloss: 1.12525\n",
      "[1765]\tvalid_0's multi_logloss: 1.12524\n",
      "[1766]\tvalid_0's multi_logloss: 1.12524\n",
      "[1767]\tvalid_0's multi_logloss: 1.12523\n",
      "[1768]\tvalid_0's multi_logloss: 1.12523\n",
      "[1769]\tvalid_0's multi_logloss: 1.12522\n",
      "[1770]\tvalid_0's multi_logloss: 1.12522\n",
      "[1771]\tvalid_0's multi_logloss: 1.12521\n",
      "[1772]\tvalid_0's multi_logloss: 1.1252\n",
      "[1773]\tvalid_0's multi_logloss: 1.1252\n",
      "[1774]\tvalid_0's multi_logloss: 1.12519\n",
      "[1775]\tvalid_0's multi_logloss: 1.12519\n",
      "[1776]\tvalid_0's multi_logloss: 1.12518\n",
      "[1777]\tvalid_0's multi_logloss: 1.12518\n",
      "[1778]\tvalid_0's multi_logloss: 1.12517\n",
      "[1779]\tvalid_0's multi_logloss: 1.12516\n",
      "[1780]\tvalid_0's multi_logloss: 1.12516\n",
      "[1781]\tvalid_0's multi_logloss: 1.12515\n",
      "[1782]\tvalid_0's multi_logloss: 1.12515\n",
      "[1783]\tvalid_0's multi_logloss: 1.12514\n",
      "[1784]\tvalid_0's multi_logloss: 1.12514\n",
      "[1785]\tvalid_0's multi_logloss: 1.12513\n",
      "[1786]\tvalid_0's multi_logloss: 1.12513\n",
      "[1787]\tvalid_0's multi_logloss: 1.12512\n",
      "[1788]\tvalid_0's multi_logloss: 1.12512\n",
      "[1789]\tvalid_0's multi_logloss: 1.12511\n",
      "[1790]\tvalid_0's multi_logloss: 1.12511\n",
      "[1791]\tvalid_0's multi_logloss: 1.1251\n",
      "[1792]\tvalid_0's multi_logloss: 1.1251\n",
      "[1793]\tvalid_0's multi_logloss: 1.12509\n",
      "[1794]\tvalid_0's multi_logloss: 1.12509\n",
      "[1795]\tvalid_0's multi_logloss: 1.12508\n",
      "[1796]\tvalid_0's multi_logloss: 1.12508\n",
      "[1797]\tvalid_0's multi_logloss: 1.12507\n",
      "[1798]\tvalid_0's multi_logloss: 1.12507\n",
      "[1799]\tvalid_0's multi_logloss: 1.12506\n",
      "[1800]\tvalid_0's multi_logloss: 1.12506\n",
      "[1801]\tvalid_0's multi_logloss: 1.12505\n",
      "[1802]\tvalid_0's multi_logloss: 1.12505\n",
      "[1803]\tvalid_0's multi_logloss: 1.12504\n",
      "[1804]\tvalid_0's multi_logloss: 1.12504\n",
      "[1805]\tvalid_0's multi_logloss: 1.12503\n",
      "[1806]\tvalid_0's multi_logloss: 1.12503\n",
      "[1807]\tvalid_0's multi_logloss: 1.12502\n",
      "[1808]\tvalid_0's multi_logloss: 1.12502\n",
      "[1809]\tvalid_0's multi_logloss: 1.12501\n",
      "[1810]\tvalid_0's multi_logloss: 1.12501\n",
      "[1811]\tvalid_0's multi_logloss: 1.125\n",
      "[1812]\tvalid_0's multi_logloss: 1.125\n",
      "[1813]\tvalid_0's multi_logloss: 1.12499\n",
      "[1814]\tvalid_0's multi_logloss: 1.12499\n",
      "[1815]\tvalid_0's multi_logloss: 1.12498\n",
      "[1816]\tvalid_0's multi_logloss: 1.12498\n",
      "[1817]\tvalid_0's multi_logloss: 1.12497\n",
      "[1818]\tvalid_0's multi_logloss: 1.12497\n",
      "[1819]\tvalid_0's multi_logloss: 1.12496\n",
      "[1820]\tvalid_0's multi_logloss: 1.12496\n",
      "[1821]\tvalid_0's multi_logloss: 1.12495\n",
      "[1822]\tvalid_0's multi_logloss: 1.12495\n",
      "[1823]\tvalid_0's multi_logloss: 1.12494\n",
      "[1824]\tvalid_0's multi_logloss: 1.12494\n",
      "[1825]\tvalid_0's multi_logloss: 1.12493\n",
      "[1826]\tvalid_0's multi_logloss: 1.12493\n",
      "[1827]\tvalid_0's multi_logloss: 1.12492\n",
      "[1828]\tvalid_0's multi_logloss: 1.12492\n",
      "[1829]\tvalid_0's multi_logloss: 1.12492\n",
      "[1830]\tvalid_0's multi_logloss: 1.12491\n",
      "[1831]\tvalid_0's multi_logloss: 1.12491\n",
      "[1832]\tvalid_0's multi_logloss: 1.1249\n",
      "[1833]\tvalid_0's multi_logloss: 1.12489\n",
      "[1834]\tvalid_0's multi_logloss: 1.12489\n",
      "[1835]\tvalid_0's multi_logloss: 1.12488\n",
      "[1836]\tvalid_0's multi_logloss: 1.12488\n",
      "[1837]\tvalid_0's multi_logloss: 1.12487\n",
      "[1838]\tvalid_0's multi_logloss: 1.12487\n",
      "[1839]\tvalid_0's multi_logloss: 1.12486\n",
      "[1840]\tvalid_0's multi_logloss: 1.12486\n",
      "[1841]\tvalid_0's multi_logloss: 1.12485\n",
      "[1842]\tvalid_0's multi_logloss: 1.12485\n",
      "[1843]\tvalid_0's multi_logloss: 1.12484\n",
      "[1844]\tvalid_0's multi_logloss: 1.12484\n",
      "[1845]\tvalid_0's multi_logloss: 1.12483\n",
      "[1846]\tvalid_0's multi_logloss: 1.12483\n",
      "[1847]\tvalid_0's multi_logloss: 1.12482\n",
      "[1848]\tvalid_0's multi_logloss: 1.12482\n",
      "[1849]\tvalid_0's multi_logloss: 1.12481\n",
      "[1850]\tvalid_0's multi_logloss: 1.12481\n",
      "[1851]\tvalid_0's multi_logloss: 1.1248\n",
      "[1852]\tvalid_0's multi_logloss: 1.1248\n",
      "[1853]\tvalid_0's multi_logloss: 1.12479\n",
      "[1854]\tvalid_0's multi_logloss: 1.12479\n",
      "[1855]\tvalid_0's multi_logloss: 1.12478\n",
      "[1856]\tvalid_0's multi_logloss: 1.12478\n",
      "[1857]\tvalid_0's multi_logloss: 1.12477\n",
      "[1858]\tvalid_0's multi_logloss: 1.12477\n",
      "[1859]\tvalid_0's multi_logloss: 1.12476\n",
      "[1860]\tvalid_0's multi_logloss: 1.12476\n",
      "[1861]\tvalid_0's multi_logloss: 1.12475\n",
      "[1862]\tvalid_0's multi_logloss: 1.12475\n",
      "[1863]\tvalid_0's multi_logloss: 1.12474\n",
      "[1864]\tvalid_0's multi_logloss: 1.12474\n",
      "[1865]\tvalid_0's multi_logloss: 1.12473\n",
      "[1866]\tvalid_0's multi_logloss: 1.12473\n",
      "[1867]\tvalid_0's multi_logloss: 1.12473\n",
      "[1868]\tvalid_0's multi_logloss: 1.12472\n",
      "[1869]\tvalid_0's multi_logloss: 1.12472\n",
      "[1870]\tvalid_0's multi_logloss: 1.12471\n",
      "[1871]\tvalid_0's multi_logloss: 1.12471\n",
      "[1872]\tvalid_0's multi_logloss: 1.1247\n",
      "[1873]\tvalid_0's multi_logloss: 1.1247\n",
      "[1874]\tvalid_0's multi_logloss: 1.1247\n",
      "[1875]\tvalid_0's multi_logloss: 1.12469\n",
      "[1876]\tvalid_0's multi_logloss: 1.12469\n",
      "[1877]\tvalid_0's multi_logloss: 1.12468\n",
      "[1878]\tvalid_0's multi_logloss: 1.12468\n",
      "[1879]\tvalid_0's multi_logloss: 1.12467\n",
      "[1880]\tvalid_0's multi_logloss: 1.12467\n",
      "[1881]\tvalid_0's multi_logloss: 1.12466\n",
      "[1882]\tvalid_0's multi_logloss: 1.12466\n",
      "[1883]\tvalid_0's multi_logloss: 1.12465\n",
      "[1884]\tvalid_0's multi_logloss: 1.12465\n",
      "[1885]\tvalid_0's multi_logloss: 1.12464\n",
      "[1886]\tvalid_0's multi_logloss: 1.12464\n",
      "[1887]\tvalid_0's multi_logloss: 1.12464\n",
      "[1888]\tvalid_0's multi_logloss: 1.12463\n",
      "[1889]\tvalid_0's multi_logloss: 1.12463\n",
      "[1890]\tvalid_0's multi_logloss: 1.12462\n",
      "[1891]\tvalid_0's multi_logloss: 1.12462\n",
      "[1892]\tvalid_0's multi_logloss: 1.12461\n",
      "[1893]\tvalid_0's multi_logloss: 1.12461\n",
      "[1894]\tvalid_0's multi_logloss: 1.1246\n",
      "[1895]\tvalid_0's multi_logloss: 1.1246\n",
      "[1896]\tvalid_0's multi_logloss: 1.12459\n",
      "[1897]\tvalid_0's multi_logloss: 1.12459\n",
      "[1898]\tvalid_0's multi_logloss: 1.12458\n",
      "[1899]\tvalid_0's multi_logloss: 1.12458\n",
      "[1900]\tvalid_0's multi_logloss: 1.12457\n",
      "[1901]\tvalid_0's multi_logloss: 1.12457\n",
      "[1902]\tvalid_0's multi_logloss: 1.12456\n",
      "[1903]\tvalid_0's multi_logloss: 1.12456\n",
      "[1904]\tvalid_0's multi_logloss: 1.12455\n",
      "[1905]\tvalid_0's multi_logloss: 1.12455\n",
      "[1906]\tvalid_0's multi_logloss: 1.12455\n",
      "[1907]\tvalid_0's multi_logloss: 1.12454\n",
      "[1908]\tvalid_0's multi_logloss: 1.12454\n",
      "[1909]\tvalid_0's multi_logloss: 1.12453\n",
      "[1910]\tvalid_0's multi_logloss: 1.12453\n",
      "[1911]\tvalid_0's multi_logloss: 1.12452\n",
      "[1912]\tvalid_0's multi_logloss: 1.12452\n",
      "[1913]\tvalid_0's multi_logloss: 1.12452\n",
      "[1914]\tvalid_0's multi_logloss: 1.12451\n",
      "[1915]\tvalid_0's multi_logloss: 1.12451\n",
      "[1916]\tvalid_0's multi_logloss: 1.1245\n",
      "[1917]\tvalid_0's multi_logloss: 1.1245\n",
      "[1918]\tvalid_0's multi_logloss: 1.12449\n",
      "[1919]\tvalid_0's multi_logloss: 1.12449\n",
      "[1920]\tvalid_0's multi_logloss: 1.12449\n",
      "[1921]\tvalid_0's multi_logloss: 1.12448\n",
      "[1922]\tvalid_0's multi_logloss: 1.12448\n",
      "[1923]\tvalid_0's multi_logloss: 1.12447\n",
      "[1924]\tvalid_0's multi_logloss: 1.12447\n",
      "[1925]\tvalid_0's multi_logloss: 1.12447\n",
      "[1926]\tvalid_0's multi_logloss: 1.12446\n",
      "[1927]\tvalid_0's multi_logloss: 1.12446\n",
      "[1928]\tvalid_0's multi_logloss: 1.12445\n",
      "[1929]\tvalid_0's multi_logloss: 1.12445\n",
      "[1930]\tvalid_0's multi_logloss: 1.12444\n",
      "[1931]\tvalid_0's multi_logloss: 1.12444\n",
      "[1932]\tvalid_0's multi_logloss: 1.12444\n",
      "[1933]\tvalid_0's multi_logloss: 1.12443\n",
      "[1934]\tvalid_0's multi_logloss: 1.12443\n",
      "[1935]\tvalid_0's multi_logloss: 1.12442\n",
      "[1936]\tvalid_0's multi_logloss: 1.12442\n",
      "[1937]\tvalid_0's multi_logloss: 1.12442\n",
      "[1938]\tvalid_0's multi_logloss: 1.12441\n",
      "[1939]\tvalid_0's multi_logloss: 1.12441\n",
      "[1940]\tvalid_0's multi_logloss: 1.1244\n",
      "[1941]\tvalid_0's multi_logloss: 1.1244\n",
      "[1942]\tvalid_0's multi_logloss: 1.1244\n",
      "[1943]\tvalid_0's multi_logloss: 1.12439\n",
      "[1944]\tvalid_0's multi_logloss: 1.12439\n",
      "[1945]\tvalid_0's multi_logloss: 1.12439\n",
      "[1946]\tvalid_0's multi_logloss: 1.12438\n",
      "[1947]\tvalid_0's multi_logloss: 1.12438\n",
      "[1948]\tvalid_0's multi_logloss: 1.12437\n",
      "[1949]\tvalid_0's multi_logloss: 1.12437\n",
      "[1950]\tvalid_0's multi_logloss: 1.12436\n",
      "[1951]\tvalid_0's multi_logloss: 1.12436\n",
      "[1952]\tvalid_0's multi_logloss: 1.12436\n",
      "[1953]\tvalid_0's multi_logloss: 1.12435\n",
      "[1954]\tvalid_0's multi_logloss: 1.12435\n",
      "[1955]\tvalid_0's multi_logloss: 1.12435\n",
      "[1956]\tvalid_0's multi_logloss: 1.12434\n",
      "[1957]\tvalid_0's multi_logloss: 1.12434\n",
      "[1958]\tvalid_0's multi_logloss: 1.12434\n",
      "[1959]\tvalid_0's multi_logloss: 1.12433\n",
      "[1960]\tvalid_0's multi_logloss: 1.12433\n",
      "[1961]\tvalid_0's multi_logloss: 1.12432\n",
      "[1962]\tvalid_0's multi_logloss: 1.12432\n",
      "[1963]\tvalid_0's multi_logloss: 1.12432\n",
      "[1964]\tvalid_0's multi_logloss: 1.12431\n",
      "[1965]\tvalid_0's multi_logloss: 1.12431\n",
      "[1966]\tvalid_0's multi_logloss: 1.12431\n",
      "[1967]\tvalid_0's multi_logloss: 1.1243\n",
      "[1968]\tvalid_0's multi_logloss: 1.1243\n",
      "[1969]\tvalid_0's multi_logloss: 1.1243\n",
      "[1970]\tvalid_0's multi_logloss: 1.12429\n",
      "[1971]\tvalid_0's multi_logloss: 1.12429\n",
      "[1972]\tvalid_0's multi_logloss: 1.12428\n",
      "[1973]\tvalid_0's multi_logloss: 1.12428\n",
      "[1974]\tvalid_0's multi_logloss: 1.12428\n",
      "[1975]\tvalid_0's multi_logloss: 1.12427\n",
      "[1976]\tvalid_0's multi_logloss: 1.12427\n",
      "[1977]\tvalid_0's multi_logloss: 1.12427\n",
      "[1978]\tvalid_0's multi_logloss: 1.12426\n",
      "[1979]\tvalid_0's multi_logloss: 1.12426\n",
      "[1980]\tvalid_0's multi_logloss: 1.12426\n",
      "[1981]\tvalid_0's multi_logloss: 1.12425\n",
      "[1982]\tvalid_0's multi_logloss: 1.12425\n",
      "[1983]\tvalid_0's multi_logloss: 1.12424\n",
      "[1984]\tvalid_0's multi_logloss: 1.12424\n",
      "[1985]\tvalid_0's multi_logloss: 1.12424\n",
      "[1986]\tvalid_0's multi_logloss: 1.12423\n",
      "[1987]\tvalid_0's multi_logloss: 1.12423\n",
      "[1988]\tvalid_0's multi_logloss: 1.12423\n",
      "[1989]\tvalid_0's multi_logloss: 1.12422\n",
      "[1990]\tvalid_0's multi_logloss: 1.12422\n",
      "[1991]\tvalid_0's multi_logloss: 1.12422\n",
      "[1992]\tvalid_0's multi_logloss: 1.12421\n",
      "[1993]\tvalid_0's multi_logloss: 1.12421\n",
      "[1994]\tvalid_0's multi_logloss: 1.12421\n",
      "[1995]\tvalid_0's multi_logloss: 1.1242\n",
      "[1996]\tvalid_0's multi_logloss: 1.1242\n",
      "[1997]\tvalid_0's multi_logloss: 1.1242\n",
      "[1998]\tvalid_0's multi_logloss: 1.12419\n",
      "[1999]\tvalid_0's multi_logloss: 1.12419\n",
      "[2000]\tvalid_0's multi_logloss: 1.12418\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's multi_logloss: 1.12418\n"
     ]
    }
   ],
   "source": [
    "lgb_model = lightgbm.train(parameters,\n",
    "                       train_data,\n",
    "                       valid_sets=test_data,\n",
    "                       num_boost_round=2000,\n",
    "                       early_stopping_rounds=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_lgbm = lgb_model.predict( test_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 1, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vals_predicted_lgbm = []\n",
    "\n",
    "for item in y_predicted_lgbm:\n",
    "    y_vals_predicted_lgbm.append( np.argmax( item ) )\n",
    "\n",
    "y_vals_predicted_lgbm[ : 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 0, 1, 3, 0, 3, 0, 1, 4], dtype=int64)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[ : 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5817265446797274\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", str(accuracy_score( test_y, y_vals_predicted_lgbm ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output.\n",
    "Ensembles have given accuracy no more than 0.64, like basic classification algorithms.\n",
    "I suppose, that ensembles need precise input parametras tuning. Due to limited computational power of my PC, I have decided to stop with this results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
